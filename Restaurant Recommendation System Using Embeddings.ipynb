{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restaurant Recommendation System Using Embeddings \n",
    "### Anirudh Mehrotra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:53:30.247893Z",
     "iopub.status.busy": "2024-03-03T23:53:30.247075Z",
     "iopub.status.idle": "2024-03-03T23:53:30.593264Z",
     "shell.execute_reply": "2024-03-03T23:53:30.592485Z",
     "shell.execute_reply.started": "2024-03-03T23:53:30.247863Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ast\n",
    "import json\n",
    "import folium\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:53:34.778418Z",
     "iopub.status.busy": "2024-03-03T23:53:34.777767Z",
     "iopub.status.idle": "2024-03-03T23:53:36.038475Z",
     "shell.execute_reply": "2024-03-03T23:53:36.037497Z",
     "shell.execute_reply.started": "2024-03-03T23:53:34.778369Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-8BBGnBoz5-K1WaM5Cgaw</td>\n",
       "      <td>DUxCdkXnwYEzHZvT8MyvIw</td>\n",
       "      <td>ju4YP8SLdR_BmWr_-Xh83Q</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Best pho in Santa Barbara County.  Staff are g...</td>\n",
       "      <td>2018-07-27 00:09:23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>k--beJRNBZzFklRoppa2MA</td>\n",
       "      <td>SAgf1IxxuomOWSIDzy07pQ</td>\n",
       "      <td>uE40984_YDgVvPeRpFcCaQ</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>We came for the hot chicken but were won over ...</td>\n",
       "      <td>2014-02-26 13:05:47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qmr304jvtYetK5i_Djrx_A</td>\n",
       "      <td>cMkPQZVDOibs2bz8St7Acg</td>\n",
       "      <td>JvawJ9bSr22xn4R9oLvl_w</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I really should have used my better judgement ...</td>\n",
       "      <td>2014-02-26 22:33:39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KXNdht_of5t-Dh1eoaeYHQ</td>\n",
       "      <td>9m13F_RCcz_r48tQH82I5A</td>\n",
       "      <td>bdfZdB2MTXlT6-RBjSIpQg</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>This place is relatively smaller than other ph...</td>\n",
       "      <td>2013-12-09 08:12:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>asJ8k1sm8jO01bi-s5JW8g</td>\n",
       "      <td>goySBsZ3QJfSaElPIDIzLw</td>\n",
       "      <td>14ZGwnDyydXdSBsLXpSUrA</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Best Southeast restaurant in Philadelphia. The...</td>\n",
       "      <td>2011-06-03 03:54:54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  A-8BBGnBoz5-K1WaM5Cgaw  DUxCdkXnwYEzHZvT8MyvIw  ju4YP8SLdR_BmWr_-Xh83Q   \n",
       "1  k--beJRNBZzFklRoppa2MA  SAgf1IxxuomOWSIDzy07pQ  uE40984_YDgVvPeRpFcCaQ   \n",
       "2  qmr304jvtYetK5i_Djrx_A  cMkPQZVDOibs2bz8St7Acg  JvawJ9bSr22xn4R9oLvl_w   \n",
       "3  KXNdht_of5t-Dh1eoaeYHQ  9m13F_RCcz_r48tQH82I5A  bdfZdB2MTXlT6-RBjSIpQg   \n",
       "4  asJ8k1sm8jO01bi-s5JW8g  goySBsZ3QJfSaElPIDIzLw  14ZGwnDyydXdSBsLXpSUrA   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      5       2      0     1   \n",
       "1      5       0      0     0   \n",
       "2      3       0      0     0   \n",
       "3      3       0      0     0   \n",
       "4      5       0      0     0   \n",
       "\n",
       "                                                text                 date  \n",
       "0  Best pho in Santa Barbara County.  Staff are g...  2018-07-27 00:09:23  \n",
       "1  We came for the hot chicken but were won over ...  2014-02-26 13:05:47  \n",
       "2  I really should have used my better judgement ...  2014-02-26 22:33:39  \n",
       "3  This place is relatively smaller than other ph...  2013-12-09 08:12:28  \n",
       "4  Best Southeast restaurant in Philadelphia. The...  2011-06-03 03:54:54  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training data\n",
    "df_train = pd.read_csv(\"reviews_train.csv\", sep='\\t', encoding = 'ISO-8859-1')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:53:44.281880Z",
     "iopub.status.busy": "2024-03-03T23:53:44.281488Z",
     "iopub.status.idle": "2024-03-03T23:53:44.581021Z",
     "shell.execute_reply": "2024-03-03T23:53:44.580078Z",
     "shell.execute_reply.started": "2024-03-03T23:53:44.281849Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37039</td>\n",
       "      <td>8QSAs3yVhcNS0y1fWSn41Q</td>\n",
       "      <td>BY_7xEliSP5iEig9bemaKw</td>\n",
       "      <td>e86IBzGCsrnhJbD_wELj7w</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>The main course was actually very tasty and th...</td>\n",
       "      <td>2011-01-16 20:23:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19778</td>\n",
       "      <td>-lNpxdJNrvMtZ_RTvT2NtA</td>\n",
       "      <td>djOl6zKvKdbt4lNnDKUXJg</td>\n",
       "      <td>z22hSRptt_DS0nWjsIka2A</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Outback is my favorite steakhouse. I've dined ...</td>\n",
       "      <td>2015-05-13 17:03:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80124</td>\n",
       "      <td>7Ylcy1txacpnY76275KqQw</td>\n",
       "      <td>1iokf9rM43YAwxsa8bp1OQ</td>\n",
       "      <td>jRLskcm_icZIKs81mYC4iQ</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>I absolutely love Ethiopian, I'd eat it every ...</td>\n",
       "      <td>2015-04-22 17:26:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35507</td>\n",
       "      <td>9JrJF-YHl44WJtZxaArteQ</td>\n",
       "      <td>NbcOw8Scs1AQcRR9uzlCPw</td>\n",
       "      <td>H47H_73y7aZ9KHpzct-xBg</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>I was pleasantly surprised by this place , I l...</td>\n",
       "      <td>2018-05-20 00:10:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35251</td>\n",
       "      <td>r3GB-Kg5UL_tOKdkM-nZvA</td>\n",
       "      <td>yymYLENYLOHwDRAxZvU3vA</td>\n",
       "      <td>B-DiQpcSTJ7oMMnwzbAGTQ</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Omg omg, I would marry the man that would brin...</td>\n",
       "      <td>2018-07-09 23:56:46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               review_id                 user_id  \\\n",
       "0       37039  8QSAs3yVhcNS0y1fWSn41Q  BY_7xEliSP5iEig9bemaKw   \n",
       "1       19778  -lNpxdJNrvMtZ_RTvT2NtA  djOl6zKvKdbt4lNnDKUXJg   \n",
       "2       80124  7Ylcy1txacpnY76275KqQw  1iokf9rM43YAwxsa8bp1OQ   \n",
       "3       35507  9JrJF-YHl44WJtZxaArteQ  NbcOw8Scs1AQcRR9uzlCPw   \n",
       "4       35251  r3GB-Kg5UL_tOKdkM-nZvA  yymYLENYLOHwDRAxZvU3vA   \n",
       "\n",
       "              business_id  stars  useful  funny  cool  \\\n",
       "0  e86IBzGCsrnhJbD_wELj7w      3       1      0     0   \n",
       "1  z22hSRptt_DS0nWjsIka2A      5       0      0     0   \n",
       "2  jRLskcm_icZIKs81mYC4iQ      4       5      3     3   \n",
       "3  H47H_73y7aZ9KHpzct-xBg      4       0      0     0   \n",
       "4  B-DiQpcSTJ7oMMnwzbAGTQ      5       0      0     0   \n",
       "\n",
       "                                                text                 date  \n",
       "0  The main course was actually very tasty and th...  2011-01-16 20:23:33  \n",
       "1  Outback is my favorite steakhouse. I've dined ...  2015-05-13 17:03:27  \n",
       "2  I absolutely love Ethiopian, I'd eat it every ...  2015-04-22 17:26:46  \n",
       "3  I was pleasantly surprised by this place , I l...  2018-05-20 00:10:30  \n",
       "4  Omg omg, I would marry the man that would brin...  2018-07-09 23:56:46  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test data\n",
    "df_test = pd.read_csv(\"reviews_test_all.csv\", sep='\\t', encoding = 'ISO-8859-1')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:53:52.213293Z",
     "iopub.status.busy": "2024-03-03T23:53:52.212954Z",
     "iopub.status.idle": "2024-03-03T23:53:53.758521Z",
     "shell.execute_reply": "2024-03-03T23:53:53.757630Z",
     "shell.execute_reply.started": "2024-03-03T23:53:52.213264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pns2l4eNsfO8kk83dixA6A</td>\n",
       "      <td>Abby Rappoport, LAC, CMQ</td>\n",
       "      <td>1616 Chapala St, Ste 2</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>CA</td>\n",
       "      <td>93101</td>\n",
       "      <td>34.426679</td>\n",
       "      <td>-119.711197</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>{'ByAppointmentOnly': 'True'}</td>\n",
       "      <td>Doctors, Traditional Chinese Medicine, Naturop...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mpf3x-BjTdTEA3yCZrAYPw</td>\n",
       "      <td>The UPS Store</td>\n",
       "      <td>87 Grasso Plaza Shopping Center</td>\n",
       "      <td>Affton</td>\n",
       "      <td>MO</td>\n",
       "      <td>63123</td>\n",
       "      <td>38.551126</td>\n",
       "      <td>-90.335695</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True'}</td>\n",
       "      <td>Shipping Centers, Local Services, Notaries, Ma...</td>\n",
       "      <td>{'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tUFrWirKiKi_TAnsVWINQQ</td>\n",
       "      <td>Target</td>\n",
       "      <td>5255 E Broadway Blvd</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85711</td>\n",
       "      <td>32.223236</td>\n",
       "      <td>-110.880452</td>\n",
       "      <td>3.5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>{'BikeParking': 'True', 'BusinessAcceptsCredit...</td>\n",
       "      <td>Department Stores, Shopping, Fashion, Home &amp; G...</td>\n",
       "      <td>{'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>935 Race St</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19107</td>\n",
       "      <td>39.955505</td>\n",
       "      <td>-75.155564</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsDelivery': 'False', 'OutdoorSeati...</td>\n",
       "      <td>Restaurants, Food, Bubble Tea, Coffee &amp; Tea, B...</td>\n",
       "      <td>{'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mWMc6_wTdE0EUBKIGXDVfA</td>\n",
       "      <td>Perkiomen Valley Brewery</td>\n",
       "      <td>101 Walnut St</td>\n",
       "      <td>Green Lane</td>\n",
       "      <td>PA</td>\n",
       "      <td>18054</td>\n",
       "      <td>40.338183</td>\n",
       "      <td>-75.471659</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True', 'Wheelc...</td>\n",
       "      <td>Brewpubs, Breweries, Food</td>\n",
       "      <td>{'Wednesday': '14:0-22:0', 'Thursday': '16:0-2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                      name  \\\n",
       "0  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ   \n",
       "1  mpf3x-BjTdTEA3yCZrAYPw             The UPS Store   \n",
       "2  tUFrWirKiKi_TAnsVWINQQ                    Target   \n",
       "3  MTSW4McQd7CbVtyjqoe9mw        St Honore Pastries   \n",
       "4  mWMc6_wTdE0EUBKIGXDVfA  Perkiomen Valley Brewery   \n",
       "\n",
       "                           address           city state postal_code  \\\n",
       "0           1616 Chapala St, Ste 2  Santa Barbara    CA       93101   \n",
       "1  87 Grasso Plaza Shopping Center         Affton    MO       63123   \n",
       "2             5255 E Broadway Blvd         Tucson    AZ       85711   \n",
       "3                      935 Race St   Philadelphia    PA       19107   \n",
       "4                    101 Walnut St     Green Lane    PA       18054   \n",
       "\n",
       "    latitude   longitude  stars  review_count  is_open  \\\n",
       "0  34.426679 -119.711197    5.0             7        0   \n",
       "1  38.551126  -90.335695    3.0            15        1   \n",
       "2  32.223236 -110.880452    3.5            22        0   \n",
       "3  39.955505  -75.155564    4.0            80        1   \n",
       "4  40.338183  -75.471659    4.5            13        1   \n",
       "\n",
       "                                          attributes  \\\n",
       "0                      {'ByAppointmentOnly': 'True'}   \n",
       "1             {'BusinessAcceptsCreditCards': 'True'}   \n",
       "2  {'BikeParking': 'True', 'BusinessAcceptsCredit...   \n",
       "3  {'RestaurantsDelivery': 'False', 'OutdoorSeati...   \n",
       "4  {'BusinessAcceptsCreditCards': 'True', 'Wheelc...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Doctors, Traditional Chinese Medicine, Naturop...   \n",
       "1  Shipping Centers, Local Services, Notaries, Ma...   \n",
       "2  Department Stores, Shopping, Fashion, Home & G...   \n",
       "3  Restaurants, Food, Bubble Tea, Coffee & Tea, B...   \n",
       "4                          Brewpubs, Breweries, Food   \n",
       "\n",
       "                                               hours  \n",
       "0                                                NaN  \n",
       "1  {'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...  \n",
       "2  {'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...  \n",
       "3  {'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...  \n",
       "4  {'Wednesday': '14:0-22:0', 'Thursday': '16:0-2...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Businesses data\n",
    "df_businesses = pd.read_csv(\"businesses.csv\", sep='\\t', encoding = 'ISO-8859-1', index_col=0)\n",
    "print (len(df_businesses))\n",
    "df_businesses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:53:57.125255Z",
     "iopub.status.busy": "2024-03-03T23:53:57.124576Z",
     "iopub.status.idle": "2024-03-03T23:54:03.827584Z",
     "shell.execute_reply": "2024-03-03T23:54:03.826646Z",
     "shell.execute_reply.started": "2024-03-03T23:53:57.125222Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>yelping_since</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "      <th>friends</th>\n",
       "      <th>...</th>\n",
       "      <th>compliment_more</th>\n",
       "      <th>compliment_profile</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>compliment_list</th>\n",
       "      <th>compliment_note</th>\n",
       "      <th>compliment_plain</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>compliment_funny</th>\n",
       "      <th>compliment_writer</th>\n",
       "      <th>compliment_photos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>qVc8ODYU5SZjKXVBgXdI7w</td>\n",
       "      <td>Walker</td>\n",
       "      <td>585</td>\n",
       "      <td>2007-01-25 16:47:26</td>\n",
       "      <td>7217</td>\n",
       "      <td>1259</td>\n",
       "      <td>5994</td>\n",
       "      <td>2007</td>\n",
       "      <td>NSCy54eWehBJyZdG2iE84w, pe42u7DcCH2QmI81NX-8qA...</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>18</td>\n",
       "      <td>232</td>\n",
       "      <td>844</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>239</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>j14WgRoU_-2ZE1aw1dXrJg</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>4333</td>\n",
       "      <td>2009-01-25 04:35:42</td>\n",
       "      <td>43091</td>\n",
       "      <td>13066</td>\n",
       "      <td>27281</td>\n",
       "      <td>2009,2010,2011,2012,2013,2014,2015,2016,2017,2...</td>\n",
       "      <td>ueRPE0CX75ePGMqOFVj6IQ, 52oH4DrRvzzl8wh5UXyU0A...</td>\n",
       "      <td>...</td>\n",
       "      <td>264</td>\n",
       "      <td>184</td>\n",
       "      <td>157</td>\n",
       "      <td>251</td>\n",
       "      <td>1847</td>\n",
       "      <td>7054</td>\n",
       "      <td>3131</td>\n",
       "      <td>3131</td>\n",
       "      <td>1521</td>\n",
       "      <td>1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2WnXYQFK0hXEoTxPtV2zvg</td>\n",
       "      <td>Steph</td>\n",
       "      <td>665</td>\n",
       "      <td>2008-07-25 10:41:00</td>\n",
       "      <td>2086</td>\n",
       "      <td>1010</td>\n",
       "      <td>1003</td>\n",
       "      <td>2009,2010,2011,2012,2013</td>\n",
       "      <td>LuO3Bn4f3rlhyHIaNfTlnA, j9B4XdHUhDfTKVecyWQgyA...</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>96</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SZDeASXq7o05mMNLshsdIA</td>\n",
       "      <td>Gwen</td>\n",
       "      <td>224</td>\n",
       "      <td>2005-11-29 04:38:33</td>\n",
       "      <td>512</td>\n",
       "      <td>330</td>\n",
       "      <td>299</td>\n",
       "      <td>2009,2010,2011</td>\n",
       "      <td>enx1vVPnfdNUdPho6PH_wg, 4wOcvMLtU6a9Lslggq74Vg...</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>hA5lMy-EnncsH4JoR-hFGQ</td>\n",
       "      <td>Karen</td>\n",
       "      <td>79</td>\n",
       "      <td>2007-01-05 19:40:59</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PBK4q9KEEBHhFvSXCUirIw, 3FWPpM7KU1gXeOM_ZbYMbA...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                 user_id    name  review_count  \\\n",
       "0           0  qVc8ODYU5SZjKXVBgXdI7w  Walker           585   \n",
       "1           1  j14WgRoU_-2ZE1aw1dXrJg  Daniel          4333   \n",
       "2           2  2WnXYQFK0hXEoTxPtV2zvg   Steph           665   \n",
       "3           3  SZDeASXq7o05mMNLshsdIA    Gwen           224   \n",
       "4           4  hA5lMy-EnncsH4JoR-hFGQ   Karen            79   \n",
       "\n",
       "         yelping_since  useful  funny   cool  \\\n",
       "0  2007-01-25 16:47:26    7217   1259   5994   \n",
       "1  2009-01-25 04:35:42   43091  13066  27281   \n",
       "2  2008-07-25 10:41:00    2086   1010   1003   \n",
       "3  2005-11-29 04:38:33     512    330    299   \n",
       "4  2007-01-05 19:40:59      29     15      7   \n",
       "\n",
       "                                               elite  \\\n",
       "0                                               2007   \n",
       "1  2009,2010,2011,2012,2013,2014,2015,2016,2017,2...   \n",
       "2                           2009,2010,2011,2012,2013   \n",
       "3                                     2009,2010,2011   \n",
       "4                                                NaN   \n",
       "\n",
       "                                             friends  ...  compliment_more  \\\n",
       "0  NSCy54eWehBJyZdG2iE84w, pe42u7DcCH2QmI81NX-8qA...  ...               65   \n",
       "1  ueRPE0CX75ePGMqOFVj6IQ, 52oH4DrRvzzl8wh5UXyU0A...  ...              264   \n",
       "2  LuO3Bn4f3rlhyHIaNfTlnA, j9B4XdHUhDfTKVecyWQgyA...  ...               13   \n",
       "3  enx1vVPnfdNUdPho6PH_wg, 4wOcvMLtU6a9Lslggq74Vg...  ...                4   \n",
       "4  PBK4q9KEEBHhFvSXCUirIw, 3FWPpM7KU1gXeOM_ZbYMbA...  ...                1   \n",
       "\n",
       "   compliment_profile  compliment_cute  compliment_list  compliment_note  \\\n",
       "0                  55               56               18              232   \n",
       "1                 184              157              251             1847   \n",
       "2                  10               17                3               66   \n",
       "3                   1                6                2               12   \n",
       "4                   0                0                0                1   \n",
       "\n",
       "   compliment_plain  compliment_cool  compliment_funny  compliment_writer  \\\n",
       "0               844              467               467                239   \n",
       "1              7054             3131              3131               1521   \n",
       "2                96              119               119                 35   \n",
       "3                16               26                26                 10   \n",
       "4                 1                0                 0                  0   \n",
       "\n",
       "   compliment_photos  \n",
       "0                180  \n",
       "1               1946  \n",
       "2                 18  \n",
       "3                  9  \n",
       "4                  0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Users data\n",
    "df_users = pd.read_csv(\"users.csv\", sep='\\t', encoding = 'ISO-8859-1')\n",
    "print (len(df_users))\n",
    "df_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "### Light preprocessing, by downcasesing words and removing tokens too short or too long in addition to stopwords.  It is applied to each 'text' entry in training data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:54:35.309979Z",
     "iopub.status.busy": "2024-03-03T23:54:35.309484Z",
     "iopub.status.idle": "2024-03-03T23:54:35.314732Z",
     "shell.execute_reply": "2024-03-03T23:54:35.313708Z",
     "shell.execute_reply.started": "2024-03-03T23:54:35.309946Z"
    }
   },
   "outputs": [],
   "source": [
    "# text preprocessing\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:54:47.277071Z",
     "iopub.status.busy": "2024-03-03T23:54:47.276347Z",
     "iopub.status.idle": "2024-03-03T23:54:47.298973Z",
     "shell.execute_reply": "2024-03-03T23:54:47.298028Z",
     "shell.execute_reply.started": "2024-03-03T23:54:47.277034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['went',\n",
       " 'sunday',\n",
       " 'brunch',\n",
       " 'highly',\n",
       " 'recommended',\n",
       " 'take',\n",
       " 'reservations',\n",
       " 'great',\n",
       " 'us',\n",
       " 'since',\n",
       " 'group',\n",
       " 'favorite',\n",
       " 'restaurant',\n",
       " 'nashville',\n",
       " 'breakfast',\n",
       " 'burrito',\n",
       " 'craving',\n",
       " 'another',\n",
       " 'one',\n",
       " 'ever',\n",
       " 'since',\n",
       " 'really',\n",
       " 'dont',\n",
       " 'think',\n",
       " 'go',\n",
       " 'wrong',\n",
       " 'anything',\n",
       " 'menu',\n",
       " 'service',\n",
       " 'great',\n",
       " 'little',\n",
       " 'slow',\n",
       " 'busy',\n",
       " 'sunday',\n",
       " 'morning',\n",
       " 'im',\n",
       " 'looking',\n",
       " 'forward',\n",
       " 'next',\n",
       " 'time',\n",
       " 'town',\n",
       " 'try',\n",
       " 'dinner']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# tokenize one string text\n",
    "def tokenize_text(text):\n",
    "    token_list = []\n",
    "    text_str = re.sub(r'[^\\w\\s]', '', text.lower()) # drop non-alphanumeric or non-white-space\n",
    "    for word in nltk.tokenize.word_tokenize(text_str):\n",
    "        if word not in stop_words and len(word) > 1 and len(word) < 20:\n",
    "            token_list.append(word)\n",
    "    return token_list\n",
    "\n",
    "#------------\n",
    "text1 = \"We went for Sunday Brunch, highly recommended. They take reservations  which was great for us since we were a group of 7. This was my favorite restaurant in Nashville. I had the breakfast burrito and I have been craving another one ever since! But really, I don't think you can go wrong with anything on the menu! The service was great, a little slow but it was a busy Sunday morning. I'm looking forward to the next time I am in town so I can try it for dinner!\"\n",
    "tokenize_text(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:54:53.385811Z",
     "iopub.status.busy": "2024-03-03T23:54:53.385435Z",
     "iopub.status.idle": "2024-03-03T23:56:00.032505Z",
     "shell.execute_reply": "2024-03-03T23:56:00.031471Z",
     "shell.execute_reply.started": "2024-03-03T23:54:53.385780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best', 'pho', 'santa', 'barbara', 'county', 'staff', 'great', 'drive', '3540', 'minutes', 'pho', 'would', 'drive', 'double', 'seriously', 'tho', 'pho', 'withdrawals', 'thanks', 'phamous']\n",
      "['place', 'awesome', 'right', 'walk', 'ur', 'overwhelmed', 'many', 'options', 'available', 'hard', 'choose', 'guy', 'helped', 'us', 'friendly', 'made', 'polite', 'conversation', 'lets', 'talk', 'actual', 'gelato', 'good', 'quality', 'amazing', 'especially', 'liked', 'lotus', 'cookie', 'mango', 'outside', 'place', 'hopping', 'makes', 'feel', 'like', 'ur', 'somewhere', 'tucson', 'come']\n"
     ]
    }
   ],
   "source": [
    "# Apply the tokenization function to all 'text' in the review training dataset.\n",
    "doc = df_train.text.apply(tokenize_text)\n",
    "print (doc[0])\n",
    "print (doc[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Embeddings 1**: GloVe\n",
    "## Load GloVe (https://nlp.stanford.edu/projects/glove/) and store its embeddings in memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:56:00.034391Z",
     "iopub.status.busy": "2024-03-03T23:56:00.034067Z",
     "iopub.status.idle": "2024-03-03T23:56:00.040831Z",
     "shell.execute_reply": "2024-03-03T23:56:00.039907Z",
     "shell.execute_reply.started": "2024-03-03T23:56:00.034363Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_glove(vector_len):\n",
    "    # vector_len must be 50/100/200/300.\n",
    "    GloVe = f\"glove.6B.{vector_len}d.txt\"\n",
    "    \n",
    "    embeddings_dict = {} # embeddings of all words stored in a dictionary\n",
    "\n",
    "    with open(GloVe, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = str(values[0])\n",
    "\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "            embeddings_dict[word] = vector\n",
    "    return embeddings_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain the embedding of a given word from the Glove dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:56:00.042381Z",
     "iopub.status.busy": "2024-03-03T23:56:00.041995Z",
     "iopub.status.idle": "2024-03-03T23:56:06.685751Z",
     "shell.execute_reply": "2024-03-03T23:56:06.684778Z",
     "shell.execute_reply.started": "2024-03-03T23:56:00.042348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.63591   0.28142   1.103     0.90695   0.58408  -0.66616  -0.58817\n",
      " -0.55119   1.0063   -0.22333  -0.021339  0.59643   0.020229 -0.33389\n",
      "  0.27095   0.099159 -0.62187  -0.62834   0.87429  -0.15716   0.97701\n",
      "  0.36715   0.65559   0.15535   0.22763  -1.4113   -0.65703  -0.72715\n",
      "  0.25938  -0.23776   3.3925   -0.58473  -0.34668  -1.7489   -0.015439\n",
      "  0.50899  -0.25659   0.069998  0.086402  0.395     1.0702    0.088681\n",
      "  0.54121   0.53468   0.09773  -0.25598  -0.15555   1.5154    0.81081\n",
      "  0.11142 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict = load_glove(50)  # vector length = 50\n",
    "embedding = embeddings_dict['information']\n",
    "print (embedding)\n",
    "len(embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:56:11.127707Z",
     "iopub.status.busy": "2024-03-03T23:56:11.127334Z",
     "iopub.status.idle": "2024-03-03T23:56:11.133993Z",
     "shell.execute_reply": "2024-03-03T23:56:11.133158Z",
     "shell.execute_reply.started": "2024-03-03T23:56:11.127673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.20825   0.47786   0.52196   1.0587   -0.10045  -1.1269   -1.2581\n",
      " -0.11041  -0.074125 -0.77976  -0.37942  -0.2486   -0.39224   0.42972\n",
      "  0.9806    0.12668  -1.3772   -0.22793  -0.18497   0.41014   0.96781\n",
      "  0.8916    0.84685   0.57416   0.46455  -1.7287   -0.63918   0.56256\n",
      " -0.12651   0.49711   3.3326    0.034399  0.46149  -0.44826  -1.1945\n",
      " -0.47593  -0.31927  -0.6442    0.089735  0.073952  0.70755   0.52948\n",
      " -0.12034  -0.46779   0.24722   0.28045  -0.62632   1.4458    0.51045\n",
      "  0.74156 ]\n",
      "Cosine Similarity: 0.7023798\n"
     ]
    }
   ],
   "source": [
    "# Measure the cosine similarity between 'information' and 'news'\n",
    "from numpy.linalg import norm\n",
    "\n",
    "A = embedding\n",
    "B = embeddings_dict['news']\n",
    "print (B)\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:56:15.784690Z",
     "iopub.status.busy": "2024-03-03T23:56:15.784066Z",
     "iopub.status.idle": "2024-03-03T23:56:49.069825Z",
     "shell.execute_reply": "2024-03-03T23:56:49.068888Z",
     "shell.execute_reply.started": "2024-03-03T23:56:15.784655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-3.4245e-01 -4.4337e-01  1.2016e-01 -4.4797e-01  3.6409e-01  1.9042e-01\n",
      "  3.5814e-02  7.2083e-02  3.0849e-01 -2.7113e+00  1.6265e-01 -1.6390e-01\n",
      "  1.4919e-01  3.6991e-01 -3.4511e-01 -5.0148e-02 -2.7712e-01 -2.9568e-01\n",
      "  1.9507e-02  8.5272e-02  1.6408e-01  3.4738e-01  2.8669e-01 -6.5308e-02\n",
      " -3.3220e-01 -1.2347e-01 -2.5370e-01  7.3277e-01 -2.1210e-01  5.1321e-01\n",
      " -2.3863e-01 -1.4686e-02 -9.1284e-02  1.8715e-01 -2.0645e-01 -3.5094e-01\n",
      "  1.1643e-01 -6.0074e-02  6.4171e-02 -7.6658e-01 -2.5077e-01  4.1920e-01\n",
      "  2.3099e-01  9.6431e-01 -7.1394e-02 -1.5819e-01 -5.3712e-03 -6.7648e-03\n",
      " -2.7829e-01 -1.9475e-01  5.6329e-01 -3.4195e-02 -1.8190e-01 -3.4428e-01\n",
      " -5.7025e-01  4.5278e-01  1.5301e-01 -6.8768e-02 -2.6461e-01  2.1887e-02\n",
      " -2.1543e-01  1.2986e-01  6.0415e-02  1.3248e-01  1.5046e-01 -1.2934e-01\n",
      "  3.1512e-01 -3.8397e-01 -8.2451e-02  4.8302e-01 -3.4851e-01  2.4238e-01\n",
      "  3.0626e-01 -8.2572e-04 -2.7866e-01  3.5426e-01  1.3572e-01 -1.3797e-01\n",
      " -2.1691e-01  1.1389e-01  7.3912e-02 -3.1077e-01  3.6748e-02 -1.1834e-01\n",
      " -3.6796e-01 -3.0026e-01 -2.2609e-01  1.8485e-01 -4.4717e-02  7.5791e-02\n",
      " -1.0991e+00 -7.1482e-02 -3.0355e-01  1.8438e-01  3.0160e-01  9.5749e-01\n",
      " -6.9052e-01  3.3124e-02  5.2532e-01 -4.1776e-01  7.5153e-02 -2.7676e-02\n",
      "  6.1625e-02  7.6356e-02  3.7977e-01 -4.4388e-01  5.6808e-01 -3.4848e-01\n",
      " -3.2314e-01  1.9864e-01  4.1553e-01 -3.6660e-01 -1.9122e-01 -4.0817e-01\n",
      "  3.6405e-01  3.0966e-02 -2.4846e-01  1.8856e-01  4.3162e-01  4.7249e-02\n",
      "  1.0592e-01  2.9250e-01  6.5203e-01 -4.1464e-01 -1.1387e-01  8.5953e-02\n",
      " -3.3522e-02 -3.4208e-01 -1.9195e-01  1.4766e-01 -8.0478e-02 -4.6072e-01\n",
      "  3.6896e-01 -2.4591e-01  2.1069e-01 -2.3852e-01  5.7918e-01  5.2443e-02\n",
      " -5.0777e-01  3.5401e-01 -1.3686e-01  3.2540e-02  5.0705e-01  4.0582e-02\n",
      " -1.0538e-01 -1.6362e-01 -2.7705e-02 -4.1447e-02  1.8581e-01  1.7167e-01\n",
      "  7.7077e-01  2.2775e-01  5.3597e-01  2.0227e-02 -3.5959e-01 -2.6842e-01\n",
      "  2.8899e-01 -2.0368e-02 -2.6251e-01 -5.3978e-01  7.9106e-02 -4.4467e-01\n",
      "  1.8447e-01 -7.2683e-01  1.4048e-01  2.4605e-01 -1.8244e-01 -3.3339e-02\n",
      " -1.5976e-01  8.2808e-01 -3.3068e-01 -3.9409e-01 -7.2875e-01  1.3650e-01\n",
      "  7.3705e-02 -4.1694e-01  2.0497e-01 -2.8466e-01 -1.7300e-01 -4.5633e-01\n",
      " -3.9780e-01 -2.1667e-01 -7.4823e-02  7.2075e-03 -5.2962e-01 -3.6050e-01\n",
      "  2.0984e-02 -4.9244e-01  4.1476e-01  2.6242e-01  1.7144e-01  3.5992e-01\n",
      " -2.0748e-01 -1.5984e-01  1.3455e-01  9.8380e-02  4.2048e-01 -1.0819e-01\n",
      " -3.7142e-01 -1.2078e-01 -2.6310e-01 -2.9245e-01 -2.9519e-01 -1.2661e-01\n",
      "  1.0461e-01  1.0131e-02 -7.9854e-01  2.6404e-01 -7.0713e-02 -4.0303e-01\n",
      " -1.9789e-01 -6.4404e-01  4.9570e-01 -1.1269e-01 -1.4252e-01 -7.0523e-02\n",
      "  1.5215e-01  5.9887e-01  2.2761e-01  9.0488e-01 -5.0598e-01  2.1594e-02\n",
      " -1.5444e-01 -3.4074e-02  4.4790e-01  8.0478e-02 -1.4864e-01 -1.3243e-01\n",
      "  4.3537e-01  6.2543e-02 -3.3960e-01 -2.7226e-02  1.7765e-01 -1.9225e-01\n",
      "  6.9241e-02 -3.8330e-01 -8.3615e-02 -4.0143e-01 -5.4027e-01  2.1744e-01\n",
      "  1.0310e-01  3.6487e-01  9.3685e-01 -7.4380e-02 -1.6565e-01 -1.7320e-01\n",
      " -3.5892e-03 -1.4245e-01 -1.8104e-02  6.0190e-01  1.0074e-01 -2.3653e-01\n",
      " -4.5296e-01 -3.9044e-01  2.3827e-01  9.4715e-02  6.1864e-02 -1.5222e-01\n",
      "  3.4283e-02  2.5517e-01 -2.4566e-01 -6.6996e-02  2.8142e-01  1.6631e-01\n",
      "  4.4565e-02  1.6217e-01 -1.4133e-01  8.1484e-02  3.3569e-01 -4.3887e-02\n",
      " -2.5484e-01 -1.4681e-01  2.7192e-01  3.5297e-01 -2.9797e-02 -7.9619e-02\n",
      " -2.1147e+00  3.5684e-01  8.1569e-01 -4.5375e-01 -4.3235e-01 -1.3817e-01\n",
      "  5.6413e-01 -1.1334e-01  5.2338e-01 -7.9187e-01  4.3943e-01  1.4345e-01\n",
      " -2.7883e-03 -4.1992e-01  3.7763e-01 -3.8431e-01  1.2515e-02  2.4784e-01\n",
      "  3.1329e-01  2.1109e-01 -3.6895e-01 -2.9441e-01 -2.8988e-01 -7.3416e-02]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict = load_glove(300) # vector/embedding length = 300\n",
    "embedding = embeddings_dict['information']\n",
    "print (embedding)\n",
    "len(embeddings_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:56:53.380484Z",
     "iopub.status.busy": "2024-03-03T23:56:53.379656Z",
     "iopub.status.idle": "2024-03-03T23:56:53.389205Z",
     "shell.execute_reply": "2024-03-03T23:56:53.388292Z",
     "shell.execute_reply.started": "2024-03-03T23:56:53.380451Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-4.1681e-01  1.9399e-01  2.2356e-01  1.8028e-01  3.3988e-01  1.5870e-01\n",
      " -2.1046e-01  4.2863e-01 -4.1325e-02 -1.8492e+00 -7.3289e-02  1.0118e-02\n",
      "  4.5465e-01  7.2215e-01  6.3270e-01  2.2182e-04 -2.4905e-01  4.3111e-02\n",
      "  3.3807e-01 -2.5771e-01  1.3360e-01  2.2773e-01  7.3658e-01  7.9592e-01\n",
      "  1.1137e-02 -1.1906e-01 -8.9547e-03  1.7780e-01  1.8806e-01 -5.1765e-01\n",
      " -3.8165e-01 -2.5147e-01  8.0401e-01  3.5761e-01 -1.4509e+00 -1.8325e-01\n",
      " -4.0522e-01  1.0572e-01  3.6496e-01  3.2123e-01 -6.8881e-02 -1.9882e-02\n",
      "  1.8024e-01  9.7504e-01 -8.8517e-02  2.0294e-01  9.8143e-02 -1.0290e-01\n",
      " -3.1582e-01  4.3241e-01  2.5816e-01  6.6642e-01  9.8665e-02 -5.2727e-01\n",
      " -2.8406e-02  1.1121e+00  2.5231e-01  1.2746e-01 -5.5072e-02 -7.4524e-01\n",
      "  6.8430e-01  4.0475e-01  3.6269e-01 -1.1521e-01 -2.8835e-01 -1.9462e-01\n",
      "  7.9845e-01  1.6139e-01  4.9639e-01 -5.1145e-01 -4.9031e-02  5.7478e-02\n",
      " -8.3950e-01 -2.8308e-02 -1.3099e-01 -5.4157e-02  4.9117e-01  4.0342e-01\n",
      "  5.6126e-03  8.8418e-01  5.4271e-02 -2.5825e-01 -7.7113e-02  1.7931e-02\n",
      "  1.7902e-01  3.5878e-01 -5.2626e-01 -1.9076e-01  4.1669e-01  4.9188e-01\n",
      " -3.2459e-01 -3.5685e-01 -4.3174e-01  4.8152e-01 -3.1464e-01  1.1202e-01\n",
      " -3.2594e-01  2.3822e-02  5.6457e-01  6.1948e-02  5.3550e-01  5.2148e-03\n",
      "  5.8435e-04  1.9190e-01  7.5523e-01  4.8703e-02  3.4589e-01 -7.8999e-02\n",
      "  1.5210e-01  5.3058e-01 -3.1039e-01  5.5602e-01 -4.3297e-01 -5.6521e-01\n",
      "  7.2216e-01  3.1475e-01 -9.3739e-02 -2.1133e-01  4.3157e-01 -2.7953e-01\n",
      " -6.9759e-03 -5.0825e-01  5.3043e-01 -5.2156e-03  2.1829e-01  1.9740e-01\n",
      " -3.0319e-01 -2.8901e-01 -1.2108e-01 -2.7706e-02  2.2670e-01 -6.9954e-02\n",
      "  8.6795e-02 -2.2467e-02 -3.4312e-02 -5.4845e-01 -1.4004e-01  1.3347e-01\n",
      "  3.4527e-01 -1.1244e-01 -5.9455e-01  1.8844e-01  4.8115e-01 -2.4814e-01\n",
      " -2.5927e-01  3.1575e-01  7.9491e-02  7.9388e-02  1.6280e-01 -1.0870e-01\n",
      "  1.4625e+00  1.2421e-01  6.1657e-01  1.8349e-01 -5.4536e-02 -2.1765e-03\n",
      "  6.1650e-01  5.4163e-01  3.8936e-01 -6.6113e-01  1.5401e-01  6.9491e-02\n",
      "  2.5876e-02  2.0582e-02  9.9082e-02  4.3829e-01 -1.5241e-01 -4.5575e-01\n",
      " -7.3284e-01  3.4102e-01 -3.3485e-02 -7.1792e-02 -1.4654e+00  1.9517e-01\n",
      " -4.2559e-01  2.4963e-01 -2.3010e-02 -4.6520e-03  4.2056e-01  1.4244e-01\n",
      "  3.0916e-01  6.1527e-02  2.7105e-01 -2.3951e-01 -8.5515e-02 -1.4231e-01\n",
      "  5.1520e-02 -6.4193e-01 -3.1742e-01  2.9153e-02 -4.6812e-01  2.5115e-01\n",
      " -3.7900e-01  1.0069e-01  1.1382e-01  1.7888e-01  5.4556e-01 -3.9226e-01\n",
      " -1.2292e-01  2.7650e-01  5.0619e-01 -5.9664e-01 -4.1005e-01  3.3223e-01\n",
      " -2.4255e-01  3.8859e-01 -9.1276e-01 -3.2768e-01 -2.2354e-01 -8.0835e-01\n",
      " -3.4350e-01  6.6402e-03 -1.1372e-01 -4.4160e-02  2.3715e-01 -8.4593e-02\n",
      " -1.2785e-02 -2.4520e-01  8.2838e-02  3.9935e-01  1.0303e+00  2.6207e-01\n",
      "  4.0554e-01  4.9915e-01  4.0430e-01  4.6973e-01  4.8667e-01  1.3729e-01\n",
      "  7.2543e-01  1.6263e-01  4.5574e-02  3.2311e-01  5.1623e-01 -7.1118e-01\n",
      "  5.8361e-01  1.4117e-01  4.7540e-01 -4.9879e-02 -4.7364e-01  1.7253e-02\n",
      "  1.8168e-02  1.1040e-01 -2.8521e-01 -1.8496e-01 -5.9559e-02 -2.8350e-02\n",
      " -1.9453e-01 -2.1077e-01 -1.5925e-01  4.7235e-01  3.0390e-01  7.4550e-02\n",
      "  1.0041e-01  5.1864e-02  3.3691e-01 -5.7765e-02  7.9916e-02 -8.8049e-02\n",
      "  2.1178e-01  5.2590e-02  3.0635e-01  2.5201e-01  2.7218e-01  8.0919e-02\n",
      "  2.7795e-01 -5.6630e-01 -6.8998e-02  4.2334e-01 -1.0605e-01 -1.4580e-01\n",
      " -4.9446e-02 -4.9431e-01  6.7034e-02  1.0031e-01  7.9937e-02  4.6268e-01\n",
      " -1.4800e+00  3.6872e-01  8.0627e-01  7.2137e-02 -5.8470e-01  3.2585e-02\n",
      " -3.4880e-02 -1.9778e-01  5.5059e-01 -9.8486e-01 -1.7326e-01 -5.5590e-04\n",
      " -8.5332e-02  2.5399e-01  1.7152e-01 -2.8069e-01 -2.3076e-01 -3.1558e-01\n",
      " -5.1224e-01  7.1256e-01 -3.4536e-01  1.9492e-01 -4.9913e-01  5.6455e-01]\n",
      "Cosine Similarity: 0.43174088\n"
     ]
    }
   ],
   "source": [
    "A = embedding\n",
    "B = embeddings_dict['news']\n",
    "print (B)\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Embeddings 2**: Word2Vec\n",
    "## Use Word2Vec model from Gensim, train the model with the 'text' field of the training data to create a custom word embeddings for the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-03T23:57:59.496972Z",
     "iopub.status.busy": "2024-03-03T23:57:59.496571Z",
     "iopub.status.idle": "2024-03-03T23:58:27.774547Z",
     "shell.execute_reply": "2024-03-03T23:58:27.773585Z",
     "shell.execute_reply.started": "2024-03-03T23:57:59.496939Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['best',\n",
       " 'pho',\n",
       " 'in',\n",
       " 'santa',\n",
       " 'barbara',\n",
       " 'county',\n",
       " 'staff',\n",
       " 'are',\n",
       " 'great',\n",
       " 'drive',\n",
       " 'minutes',\n",
       " 'for',\n",
       " 'the',\n",
       " 'pho',\n",
       " 'would',\n",
       " 'drive',\n",
       " 'double',\n",
       " 'seriously',\n",
       " 'tho',\n",
       " 'no',\n",
       " 'more',\n",
       " 'pho',\n",
       " 'withdrawals',\n",
       " 'thanks',\n",
       " 'phamous']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply gensim's tokenization to the texts in training and test data\n",
    "import gensim\n",
    "\n",
    "doc_train = df_train.text.apply(gensim.utils.simple_preprocess)\n",
    "doc_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Word2vec\n",
    "\n",
    "Training the word2vec model is simple. First initialize Word2vec and pass the doc. So, we are essentially passing on a list of lists. Where each list within the main list contains a set of tokens from a user review. Word2Vec uses all these tokens to internally create a vocabulary.\n",
    "\n",
    "`min_count` – Ignores all words with total frequency lower than this. `min_count=2` means that to include only those words in the Word2Vec model that appear at least twice in the corpus. Words that only occur once in the corpus are not that important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T00:00:08.221295Z",
     "iopub.status.busy": "2024-03-04T00:00:08.220485Z",
     "iopub.status.idle": "2024-03-04T00:01:41.575021Z",
     "shell.execute_reply": "2024-03-04T00:01:41.574079Z",
     "shell.execute_reply.started": "2024-03-04T00:00:08.221259Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57792915, 76256390)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# output embedding size = 50, min_count = 2\n",
    "model = gensim.models.Word2Vec(doc_train, vector_size=50, window=10, min_count=2, workers=10)\n",
    "model.train(doc_train,total_examples=len(doc),epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T00:01:46.661229Z",
     "iopub.status.busy": "2024-03-04T00:01:46.660894Z",
     "iopub.status.idle": "2024-03-04T00:01:46.669537Z",
     "shell.execute_reply": "2024-03-04T00:01:46.668371Z",
     "shell.execute_reply.started": "2024-03-04T00:01:46.661203Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.29723     0.54734135  1.1398841  -4.9755673   0.8207296  -3.2533984\n",
      "  2.1525426   5.8857265   0.35786372 -2.6901011  -0.41517246 -2.8131886\n",
      "  0.5537724   2.2947595   2.1166506  -0.11715601  0.45412186 -1.9970789\n",
      " -1.9985471   3.5602062  -1.6838204  -1.4851199   2.3134134  -1.608993\n",
      "  1.4620036   2.5549567  -2.0004323   4.176901    3.3978307   6.120522\n",
      " -1.8383319  -1.2357478   4.3623133   0.10377906 -2.9185512   1.1944854\n",
      "  1.415827    0.7359568   5.140141   -2.367191    3.4848642   0.25165075\n",
      "  0.02422247 -2.278804   -3.1142998  -4.4722605   3.1232328  -1.9301746\n",
      "  0.45980147  0.25844994]\n",
      "[-4.4704957  -2.274274    1.0376229   0.44882897 -0.7288061  -0.14478914\n",
      "  0.7676871   0.34742188 -0.6469588  -1.5454592  -1.2153357  -2.3829994\n",
      "  2.3358543   1.7785823   0.10872804 -0.01414245  0.49865752  1.600994\n",
      " -0.475373   -1.4615468  -2.3719125  -1.3529972   0.06745874  1.3583021\n",
      " -0.5199218   2.7429185  -2.5349798   2.4108562   2.3540258   1.4238753\n",
      " -0.8715525  -2.0304763   1.9735405   0.54869443  2.6681528   0.41602176\n",
      "  1.703408   -0.15538254 -1.6495641   0.7371825   0.397061    1.7243929\n",
      "  0.15673044  0.96050656 -0.3324402   1.5966182  -0.7940421   1.0461844\n",
      " -1.2381353  -0.4451953 ]\n",
      "Cosine Similarity: 0.23819408\n"
     ]
    }
   ],
   "source": [
    "# Measure the cosine similarity between 'information' and 'news'\n",
    "from numpy.linalg import norm\n",
    "\n",
    "A = model.wv['information'] \n",
    "print (A)\n",
    "B = model.wv['news']\n",
    "print (B)\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T00:01:53.413059Z",
     "iopub.status.busy": "2024-03-04T00:01:53.412216Z",
     "iopub.status.idle": "2024-03-04T00:01:53.418962Z",
     "shell.execute_reply": "2024-03-04T00:01:53.418001Z",
     "shell.execute_reply.started": "2024-03-04T00:01:53.413026Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.112097    2.5161662  -2.2774305   6.414314   -1.3511789  -3.3526843\n",
      "  3.848867   -5.8530498  -0.9755648   3.9997578  -0.9868632   2.5663872\n",
      " -4.0773783  -2.5280395   1.3120728  -1.8470261   2.8048685   4.872776\n",
      " -2.3358688  -2.7807338  -7.1429024  -3.8915823   1.0343746  -0.83543456\n",
      " -1.4001312   1.1310145  -1.2556531   4.4016314  -4.0801234  -0.53187054\n",
      " -2.2935407  -4.1592164  -4.8167524   1.1580514  -2.305076    0.35823765\n",
      "  2.9694278  -1.905421   -2.587871    1.2418319  -0.7484445   2.971731\n",
      "  3.2535284   0.883229   -5.944626   -4.402496    2.2430937   7.6270385\n",
      "  1.0499492  -3.6661077 ]\n",
      "Cosine Similarity: 0.587862\n"
     ]
    }
   ],
   "source": [
    "A = model.wv['food']\n",
    "B = model.wv['sushi']\n",
    "print (B)\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T00:02:06.757436Z",
     "iopub.status.busy": "2024-03-04T00:02:06.756492Z",
     "iopub.status.idle": "2024-03-04T00:04:19.873037Z",
     "shell.execute_reply": "2024-03-04T00:04:19.872061Z",
     "shell.execute_reply.started": "2024-03-04T00:02:06.757398Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.66728294 -0.10488506 -0.9117284  -1.7343199  -0.96295947  0.49228936\n",
      "  1.2747717  -0.39240065  0.09107962 -0.95404404 -1.0611935   1.3500797\n",
      " -0.90803444  0.6008549   1.0220027  -0.63893026  1.4461858   0.01178156\n",
      " -0.28633705 -0.15630358  0.42240393 -1.9890283  -0.17606387 -1.4696267\n",
      " -2.2937891   0.0143708   1.0840741   2.433878    0.36269525  0.03660487\n",
      "  2.001248    1.4289607   0.0209853   2.3545148  -0.99441576 -1.4926776\n",
      " -2.4937112  -0.43898344 -2.2366722   0.3055381   2.3230176  -0.7071568\n",
      "  2.0415905  -0.2844939  -1.1839508   1.2785306   2.2112544   2.2248802\n",
      " -0.74456966 -0.29452798 -1.5928805  -0.6397773   0.32857496 -1.6985784\n",
      " -1.8899299   1.57887     2.667446    1.4818647   0.55813605 -2.6092927\n",
      "  1.5437765   0.1457746  -0.73217505  0.5289028  -0.92036754 -0.23738028\n",
      "  0.3857955   1.0682045   1.3224308  -2.0912123   0.5981604   0.80643225\n",
      "  1.2558258   0.34472114 -0.9071356  -0.6526262  -1.8421632   2.6603026\n",
      " -1.2121453   0.50639594  2.0224445   0.3158537  -0.16482262 -0.21991326\n",
      " -1.532116    0.6069008   0.14161253 -2.1158624  -0.52169013 -0.28696385\n",
      " -2.3015     -1.0832356  -2.747548    0.6449223   1.3968512   1.7331637\n",
      "  0.13709657 -1.7862717   2.0509794  -0.8413219   0.6061432  -1.0938958\n",
      " -0.79974884  0.11590867 -0.2821269   1.7294432   2.628431    0.06384595\n",
      "  0.4687904  -1.0942616   0.5704863   2.2738075   0.6022008  -0.4212583\n",
      " -1.0155866   1.3961806  -0.22509505  0.36080888  0.32083142 -1.9752864\n",
      " -0.32706442  0.166073    0.19628038 -0.17197591  2.9046566   1.1067508\n",
      "  1.1984526  -1.7808347  -1.2568645   2.3806102   0.25942472 -1.3863692\n",
      "  0.24268462  0.21143787  0.09888076 -0.37784556 -2.9526129   0.69775105\n",
      "  0.5912108   0.8341649   0.14713083 -1.8094357  -1.476924    0.08720373\n",
      "  1.2621346  -1.8843442  -1.9131807  -0.38747016  0.8357359   1.7139022\n",
      " -0.28380108  1.6754813   0.26326147 -0.31770414  0.9323145   0.82435644\n",
      " -1.2004821  -0.24426621  0.9185508  -0.9075845   1.9734129   0.05957834\n",
      "  1.7449572  -0.1699132  -1.6304032  -0.61048824  1.829479    0.06965108\n",
      "  0.07460186 -0.21518703  1.4938172  -0.04544237  2.302448    0.63436145\n",
      " -1.4133239   1.3200185  -0.8548767  -1.2795191   0.08657978 -2.0795054\n",
      " -2.3019     -0.26088944  0.8486467   2.121104   -0.734913    0.31375226\n",
      " -1.1044194   0.20123383  0.7641841  -2.4016151  -2.6115303   1.0560522\n",
      " -1.0882639   2.6062179   2.5646558   1.5532347  -0.23995124  0.05617484\n",
      "  0.8067588  -0.37898234 -3.4703283   0.25168616  0.3966985   0.10527366\n",
      " -0.02221909  1.5064578   0.5265679  -1.1170007  -2.0779836  -0.0170052\n",
      "  0.38742262 -4.2296457   0.4894138  -0.05490258  0.12437727  0.9709975\n",
      " -0.26681682  0.49716341 -1.2606934   0.40951535  0.7224318   0.72967166\n",
      "  0.4418245   2.2482643   0.85020226  0.41900867  0.47135842 -2.4012096\n",
      " -0.39155    -0.81002325 -1.0567832   1.2798086   0.87718177  1.3062959\n",
      "  0.8454815   0.28167278  0.5455771   2.3698428   0.7523085  -2.6504\n",
      "  0.16003858  0.52326167  0.27973396 -0.53329694  0.04510699 -2.4341445\n",
      " -0.78899866  0.46859488  0.31287846 -0.06775859  0.3329121  -0.11598832\n",
      "  2.4486835  -1.0173393  -0.6389144   0.60872376  2.181482    1.460476\n",
      " -2.4506342  -3.3776257  -0.6034918   0.8970703   1.2363147  -0.52727413\n",
      " -2.3789115   0.05778096  0.1797286   2.0243192  -0.7380357  -0.63524795\n",
      " -2.1399956   2.542199   -1.3383423   0.93142045  0.8072676   2.181905\n",
      " -0.32542458 -0.28685805 -0.60203356 -0.23463456 -0.10559575 -0.60045063\n",
      " -0.7859792   3.143707    0.9901964   0.47709113  0.5525637   0.3695172\n",
      " -0.6749235   1.1690017   2.0067172   2.6984022  -2.8019028   0.18595107\n",
      " -2.1103997   2.0181181   0.83222646 -1.2828511   0.47551194  0.87958014]\n"
     ]
    }
   ],
   "source": [
    "# output embedding size = 300, min_count = 2\n",
    "model = gensim.models.Word2Vec(doc_train, vector_size=300, window=10, min_count=2, workers=10)\n",
    "model.train(doc_train,total_examples=len(doc),epochs=10)\n",
    "vector = model.wv['information'] \n",
    "print (vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T00:04:28.618247Z",
     "iopub.status.busy": "2024-03-04T00:04:28.617540Z",
     "iopub.status.idle": "2024-03-04T00:04:28.627121Z",
     "shell.execute_reply": "2024-03-04T00:04:28.626125Z",
     "shell.execute_reply.started": "2024-03-04T00:04:28.618211Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.66006142e-01  4.14795905e-01  3.58055472e-01 -3.99000496e-01\n",
      " -6.80128276e-01  7.77110517e-01 -9.26768124e-01  9.45654750e-01\n",
      " -1.30171925e-01 -1.13393891e+00  2.74828613e-01 -4.48610932e-01\n",
      "  7.16295764e-02  9.69849229e-01  9.40739572e-01  9.09580812e-02\n",
      " -9.89308476e-01 -5.71246207e-01  7.21447766e-01 -7.87812769e-01\n",
      " -7.96876967e-01  8.45518172e-01 -1.44345200e+00  5.38699627e-01\n",
      " -7.57263780e-01  7.28140712e-01 -6.48577809e-01  1.32008827e+00\n",
      "  4.06153798e-01  7.54855752e-01 -1.82736814e-01  1.45320904e+00\n",
      "  3.41088057e-01  4.85778004e-01 -5.80023676e-02  1.20017183e+00\n",
      "  3.45992565e-01 -2.60541558e-01  6.80725500e-02 -4.53921586e-01\n",
      "  8.16070437e-01 -1.31536222e+00  5.32338738e-01 -3.67165804e-01\n",
      "  9.58203912e-01  1.91716266e+00  4.31451470e-01  2.44152471e-01\n",
      " -4.00880054e-02  3.26511711e-01  9.06788707e-01 -3.02958310e-01\n",
      "  9.07654047e-01 -2.73276180e-01  6.38737261e-01 -7.59066641e-01\n",
      " -7.75861323e-01 -8.09660137e-01  2.54724741e-01 -6.84906304e-01\n",
      " -1.79656482e+00  1.29242852e-01 -1.06661117e+00  5.43386996e-01\n",
      " -4.80379164e-01 -9.10045087e-01 -1.66412845e-01  4.59360212e-01\n",
      "  3.41688186e-01 -4.67793524e-01 -1.06233239e+00 -2.29916885e-01\n",
      "  1.01171947e+00 -6.60428464e-01 -1.57377438e-03 -1.30099893e+00\n",
      " -6.69803143e-01  2.00730205e+00  2.57456094e-01  1.49429962e-01\n",
      "  6.28948331e-01 -3.83041471e-01  1.30554581e+00  1.09794033e+00\n",
      " -7.65037835e-01  1.21071017e+00 -8.43718529e-01 -2.81835347e-01\n",
      " -2.36765146e+00  9.80306029e-01  1.16594279e+00  3.08896095e-01\n",
      " -4.16617930e-01  6.49987161e-01  1.37992114e-01  4.35187459e-01\n",
      "  6.68534875e-01  3.00513446e-01 -1.25141895e+00 -6.57171428e-01\n",
      "  1.60082340e+00  1.12639852e-01 -4.61168528e-01  9.72164050e-03\n",
      " -4.69659239e-01  1.51742935e+00 -7.13571087e-02  5.24113476e-01\n",
      "  1.35892832e+00 -8.03716481e-01 -8.17511618e-01  1.01279235e+00\n",
      "  1.14227617e+00 -7.40213245e-02  3.81286651e-01  1.14477903e-01\n",
      "  9.90908206e-01 -9.30883527e-01 -4.23536718e-01 -1.02639091e+00\n",
      "  1.48256135e+00  4.14384305e-01 -3.40548247e-01  1.24379563e+00\n",
      "  6.74883053e-02  1.13848805e+00  1.31694353e+00 -1.08330750e+00\n",
      "  8.49781096e-01  7.25226939e-01 -4.64397758e-01  4.50381845e-01\n",
      "  7.70395637e-01 -2.00520009e-01 -6.45192146e-01  7.41761982e-01\n",
      " -2.17075646e-01  1.26437402e+00 -2.13801575e+00 -9.76618007e-02\n",
      "  5.84284782e-01 -5.92239380e-01 -1.38848329e+00 -2.24589452e-01\n",
      "  1.62470412e+00  1.21239811e-01  4.68514800e-01  2.69580573e-01\n",
      " -5.35754144e-01 -5.63598461e-02  4.23330158e-01  1.65785775e-01\n",
      "  1.45190585e+00  1.45841134e+00  9.55281436e-01  1.52657771e+00\n",
      " -8.89277086e-02 -5.52658439e-01  3.92709762e-01 -1.28473294e+00\n",
      " -1.89608842e-01 -2.43036496e-03  6.18095040e-01 -5.12706995e-01\n",
      "  1.51592696e+00  2.45349016e-02  2.96100706e-01  1.14919746e+00\n",
      "  1.80936560e-01  5.55026650e-01  4.55104351e-01 -8.01160693e-01\n",
      "  1.52463043e+00  1.47862399e+00  2.07474446e+00 -7.58894563e-01\n",
      " -2.65658706e-01 -7.88569927e-01  2.05018045e-03 -1.47834349e+00\n",
      "  3.08531165e-01 -2.40013048e-01  3.70422065e-01  1.40306580e+00\n",
      "  9.35489178e-01  3.24685842e-01 -1.48145452e-01 -1.47084737e+00\n",
      "  3.26937467e-01  1.31577408e+00 -1.49163902e+00  7.59084940e-01\n",
      "  5.07812798e-01 -3.20367843e-01 -5.80920756e-01 -1.70866936e-01\n",
      " -2.65187114e-01  8.29268217e-01  1.90339220e+00 -4.25290495e-01\n",
      " -8.42731476e-01 -2.17695427e+00 -1.01481259e+00  1.44907141e+00\n",
      " -1.42443740e+00  5.39971650e-01 -9.36444197e-03 -1.27192569e+00\n",
      "  1.07258260e+00  9.98180434e-02 -6.41288221e-01 -1.67480338e+00\n",
      " -3.08912128e-01  3.37552577e-01  4.54058796e-01 -1.23945095e-01\n",
      " -2.46533409e-01 -7.56734431e-01  1.44801185e-01 -7.14535296e-01\n",
      "  8.99144828e-01  1.17223823e+00 -5.80348134e-01 -3.55309427e-01\n",
      " -1.41886532e+00  8.35171878e-01  1.64038074e+00 -3.47676396e-01\n",
      " -1.66250408e+00  3.90314683e-02  3.44552934e-01 -1.35219026e+00\n",
      "  5.30319035e-01  1.53306234e+00 -1.31499279e+00  4.00651455e-01\n",
      " -5.41235320e-02  5.47106624e-01 -1.92050144e-01 -6.93801463e-01\n",
      " -1.07881021e+00  4.42254096e-01 -3.17911148e-01  1.42835557e-01\n",
      "  5.10193408e-01 -2.74558902e-01 -5.42950213e-01  8.50827456e-01\n",
      "  1.38564563e+00  3.10938865e-01 -9.76754874e-02 -1.03194821e+00\n",
      "  5.71178973e-01 -1.05133951e+00  2.45515287e-01 -5.13718545e-01\n",
      "  5.79689264e-01  6.00773335e-01 -3.60703140e-01 -1.60286760e+00\n",
      "  3.27681839e-01 -2.22368404e-01  2.00807214e+00  6.93143904e-01\n",
      " -7.04449296e-01  6.90723598e-01 -1.50153086e-01  1.76124227e+00\n",
      "  1.68459296e-01 -7.09957421e-01  3.92794967e-01  5.13837695e-01\n",
      " -1.37361193e+00  2.99782366e-01 -7.16175064e-02 -5.54472864e-01\n",
      "  9.17111039e-01 -4.18314189e-02 -4.06402461e-02  2.15657741e-01\n",
      "  5.11530399e-01  1.67619422e-01 -5.39066017e-01  7.17312455e-01\n",
      "  1.29636824e+00  4.66472179e-01  1.55516577e+00 -2.24357590e-01\n",
      " -1.38448167e+00  2.26130581e+00 -1.07224144e-01  1.36747921e+00\n",
      "  1.09772414e-01  1.59150437e-01 -1.64854690e-01  7.93824643e-02\n",
      "  1.55082846e+00 -4.42757905e-01  1.23302925e+00  5.93478307e-02]\n",
      "Cosine Similarity: 0.25277075\n"
     ]
    }
   ],
   "source": [
    "A = vector\n",
    "B = model.wv['news']\n",
    "print (B)\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T00:05:09.768006Z",
     "iopub.status.busy": "2024-03-04T00:05:09.767301Z",
     "iopub.status.idle": "2024-03-04T00:05:09.774520Z",
     "shell.execute_reply": "2024-03-04T00:05:09.773299Z",
     "shell.execute_reply.started": "2024-03-04T00:05:09.767971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.40860918\n"
     ]
    }
   ],
   "source": [
    "A = model.wv['food']\n",
    "B = model.wv['sushi']\n",
    "cosine = np.dot(A,B)/(norm(A)*norm(B))\n",
    "print(\"Cosine Similarity:\", cosine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1: 5 QUERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abington', 'abington township', 'affton', 'afton', 'aldan', 'algiers', 'aliso viejo', 'almonesson', 'alton', 'ambler', 'andalusia', 'antioch', 'apollo beach', 'arabi', 'arden', 'ardmore', 'arizona', 'arnold', 'arrington', 'ashland', 'ashland city', 'aston', 'atco', 'audubon', 'austin', 'avon', 'avondale', 'bala cynwyd', 'ballwin', 'balm', 'bargersville', 'barnhart', 'barrington', 'bayonet point', 'bear', 'beaumont', 'beech grove', 'beech grove,', 'bellair', 'belle chase', 'belle chasse', 'belle meade', 'belleair', 'belleair beach', 'belleair blf', 'belleair bluffs', 'belleair blufs', 'belleville', 'bellevue', 'bellmawr', 'bellville', 'belmont hills', 'bensalem', 'bensalem township', 'berkeley', 'berlin', 'berlin township', 'berry hill', 'berwyn', 'bethalto', 'bethel', 'bethel township', 'beverly', 'birchrunville', 'black jack', 'blackwood', 'blue bell', 'blvd', 'boise', 'boise (meridian)', 'boise city', 'boone', 'boothwyn', 'bordentown', 'bordentown township', 'bosie', 'boulevard', 'boyertown', 'bradenton', 'bradenton beach', 'brandon', 'breckenridge hills', 'brentwood', 'brentwood - cool springs', 'bridge city', 'bridgeport', 'bridgeton', 'bristol', 'bristol twp', 'brookhaven', 'brooklawn', 'brooklyn', 'brooksville', 'broomall', 'brownsburg', 'bryn athyn', 'bryn mawr', 'buckingham', 'buckingham township', 'bucks', 'bucks county', 'bucktown', 'burlington', 'burlington township', 'bywater', 'cahokia', 'camby', 'camden', 'cane ridge', 'carmel', \"carney's point\", 'carneys point', 'carpinteria', 'carrollwood', 'carson city', 'carversville', 'casa adobes', 'casas adobes', 'caseyville', 'castleton', 'catalina', 'catalina foothills', 'cedar brook', 'cedarbrook', 'cedars', 'center city philadelphia', 'center square', 'central tampa', 'centreville', 'cerritos', 'chadds ford', 'chalemette', 'chalfont', 'chalmette', 'charlack', 'cheltenham', 'cheltenham township', 'cherry hil', 'cherry hill', 'cherry hill,', 'chesilhurst', 'chester', 'chester heights', 'chester springs', 'chester township', 'chesterbrook', 'chesterfield', 'chestnut hill', 'chicago', 'christiana', 'churchville', 'cinnaminson', 'citrus park', 'claerwater', 'clarksboro', 'claymont', 'clayton', 'clearwater', 'clearwater beach', 'clearwater,', 'clementon', 'clermont', 'clifton heights', 'coatesville', 'cold springs', 'college place', 'collegeville', 'collingdale', 'collingswood', 'collinsville', 'colmar', 'columbia', 'columbus', 'concord township', 'concordville', 'conshohocken', 'conshohoeken', 'cornwells heights', 'cornwells hts', 'corona de tucson', 'cortaro', 'cottage hills', 'covington', 'crestwood', 'creve coeur', 'creve couer', 'crosswicks', 'croydon', 'crum lynne', 'crystal beach', 'crystal springs', 'cumberland', 'cynwyd', 'dade city', 'danboro', 'danville', 'darby', 'delanco', 'delaware county', 'delran', 'delran twp', 'delray beach', 'denver', 'deptford', 'deptford township', 'deptford twp', 'des peres', 'devon', 'devon-berwyn', 'donelson', 'douglassville', 'dover', 'downingtown', 'downingtown,', 'downtown', 'downtown indianapolis', 'doylestown', 'dresher', 'drexel', 'drexel heights', 'drexel hil', 'drexel hill', 'dublin', 'dumont', 'dunedin', 'dunnellon', 'dupo', 'e saint louis', 'e. norristown', 'eagle', 'eagle,', 'eagleville', 'earlington', 'earth city', 'east alton', 'east edmonton', 'east greenville', 'east lake', 'east lansdowne', 'east nashville', 'east norristown', 'east norriton', 'east saint louis', 'east st louis', 'east st. louis', 'east tampa', 'eastampton', 'eastampton township', 'eaux claires', 'echelon', 'eddington', 'eddystone', 'edgemont', 'edgemoor', 'edgewater park', 'edgmont', 'edmonton', 'edmundson', 'edwardsville', 'elk township', 'elkins park', 'ellisville', 'elmer', 'elmwood', 'elsmere', 'elverson', 'enoch', 'erdenheim', 'erdenheim pa', 'erial', 'essington', 'evesham', 'evesham township', 'evshm twp', 'ewing', 'ewing township', 'exton', 'fairless', 'fairless hills', 'fairmont city', 'fairmount park', 'fairview', 'fairview heights', 'fairview hts', 'fairview hts.', 'fairview village', 'falls', 'feasterville', 'feasterville trev', 'feasterville trevose', 'feasterville-trevose', 'feasterville-trevose, pa', 'feastville', 'fenton', 'ferguson', 'fernley', 'festerville', 'fieldsboro', 'fishers', 'flanders', 'florence', 'florence township', 'florissant', 'flourtown', 'folcroft', 'folsom', 'forest grove', 'forest hills', 'fort washington', 'fortville', 'fountainville', 'fox street', 'franconia', 'franklin', 'franklinville', 'frazer', 'freeburg', 'freehold', 'french quarter', 'frontenac', 'furlong', 'gallatin', 'garden city', 'gardenville', 'garnet valley', 'gentilly', 'gibbsboro', 'gibbstown', 'gibsonton', 'gilbertsville', 'gladwyne', 'glassboro', 'glen carbon', 'glen mills', 'glendale', 'glendora', 'glenmoore', 'glenmore', 'glenn mills', 'glenoldan', 'glenolden', 'glenside', 'gloucester city', 'gloucester township', 'godfrey', 'goleta', 'goodletsville', 'goodlettsville', 'gradyville', 'granite city', 'greater carrollwood', 'greater northdale', 'green hills', 'green lane', 'green park', 'green valley', 'greenbrier', 'greenfield', 'greenville', 'greenwood', 'grenloch', 'gretna', 'gulfport', 'gulph mills', 'gwynedd', 'gwynedd valley', 'had twp', 'hadden', 'haddon', 'haddon heights', 'haddon township', 'haddon twp', 'haddonfield', 'hainesport', 'hamiltion', 'hamilton', 'hamilton township', 'hammonton', 'hampton', 'hancock', 'harahan', 'harleysville', 'harrison township', 'hartford', 'hartsville', 'harvey', 'hatboro', 'hatfield', 'haverford', 'havertown', 'havertown, pa', 'hazelwood', 'hendersonville', 'hermitage', 'hernando beach', 'hi-nella', 'high ridge', 'hillsborough', 'hillsborough county', 'hilltop', 'hilltown', 'hockessin', 'holicong', 'holiday', 'holland', 'holland southampton', 'holmes', 'honey brook', 'horseshoe bend', 'horsham', 'houston', 'hudson', 'hulmeville', 'huntingdon valley', 'huntingdon valley pa', 'imperial', 'indian rocks beach', 'indian rocks beach.', 'indian shores', 'indianapolis', 'indianopolis', 'indianpolis', 'inglewood', 'isla vista', 'ivyland', 'jamison', 'jefferson', 'jefferson parish', 'jeffersonville', 'jenkintown', 'jennings', 'jobstown', 'joelton', 'kalispell', 'kenner', 'kenneth', 'kenneth city', 'kennett square', 'kimberton', 'kimmiswick', 'kimmswick', 'king of prussi', 'king of prussia', 'kings beach', 'kingston springs', 'kirkwood', 'knoxville', 'kop', 'kulpsville', 'kuna', 'la vergne', 'ladue', 'lafayette hill', 'lahaska', 'lake saint louis', 'lakeland', 'lambertville', 'land o lakes', \"land o' lakes\", \"land o'lakes\", 'land-o-lakes', 'landsdale', 'langhorne', 'lansdale', 'lansdowne', 'largo', 'largo (walsingham)', 'laurel springs', 'lavergne', 'lawnside', 'lawrence', 'lawrence township', 'lawrenceville', 'lebanon', 'lederach', 'lemay', 'lemay ferry', 'lenni', 'lester', 'levittown', 'lima', 'limerick', 'lindenwold', 'line lexington', 'linfield', 'linwood', 'lionville', 'lithia', 'liverpool', 'logan township', 'los angeles', 'los ranchitos', 'lower gwynedd', 'lower gwynedd township', 'lower merion', 'lower providence', 'lula lula', 'luling', 'lumberton', 'lutz', 'lutz fl', 'madeira beach', 'madison', 'magnolia', 'malaga', 'malvern', 'manayunk', 'manchester', 'mandeville', 'mango', 'mansfield', 'mantua', 'mantua township', 'maple glen', 'maple shade', 'maple shade nj', 'maple shade township', 'maplewood', 'marana', 'marcus hook', 'marlborough', 'marlton', 'marrero', 'marshallton', 'martinsville', 'maryland heights', 'maryville', 'masaryktown', 'mascoutah', 'mc cordsville', 'mccarran', 'mccordsville', 'meadowbrook', 'mechanicsville', 'medford', 'medford lakes', 'media', 'mehlville', 'mehville', 'melrose park', 'mendenhall', 'meraux', 'mercerville', 'merchantville', 'meridan', 'meridian', 'merion park', 'merion station', 'metairie', 'metarie', 'meterie', 'mickleton', 'middle city west', 'millstadt', 'milmont park', 'mission canyon', 'mississauga', 'monroe township', 'monroeville', 'monrovia', 'mont clare', 'montchanin', 'montecito', 'montgomery', 'montgomery township', 'montgomeryville', 'moorestown', 'moorestown-lenola', 'mooresville', 'morrisville', 'morton', 'mount ephraim', 'mount holly', 'mount juliet', 'mount laurel', 'mount laurel township', 'mount lemmon', 'mount royal', 'mt ephraim', 'mt holly', 'mt juliet', 'mt laurel', 'mt laurel township', 'mt laurel twp, nj', 'mt. airy', 'mt. ephraim', 'mt. holly', 'mt. juliet', 'mt. laurel', 'mt.juliet', 'mt.laurel', 'mulberry', 'mullica hill', 'murfreesboro', 'n redington bch', 'n redngtn bch', 'nampa', 'narberth', 'nashville', 'nashville ap', 'nashville,', 'nashville-davidson metropolitan government (balance)', 'national park', 'nevada', 'new berlinville', 'new britain', 'new castle', 'new hope', 'new jersey', 'new orlaens', 'new orleans', 'new palestine', 'new port richey', 'new prt rchy', 'new pt richey', 'new washoe city', 'new whiteland', 'newark', 'newfield', 'newport', 'newton square', 'newtown', 'newtown square', 'newtown township', 'nixa', 'noblesville', 'nolensville', 'nolenville', 'normandy', 'norristown', 'norriton', 'norritown', 'north coventry', 'north maple shade', 'north marlton', 'north redington bch', 'north redington beach', 'north wales', 'norwood', 'nw edmonton', 'o fallon', \"o' fallon\", \"o'fallon\", 'oakford', 'oaklandon', 'oaklyn', 'oaks', 'oakville', 'odessa', 'ofallon', 'old hickory', 'old strathcona', 'oldmans', 'oldmans township', 'oldsmar', 'olivette', 'oracle', 'oreland', 'oro valley', 'overland', 'oxnard', 'ozona', 'pagedale', 'palm harbor', 'palm harbor, fl', 'palmetto', 'palmyra', 'paoli', 'parker ford', 'parkside', 'pasadena', 'pass-a-grille', 'pass-a-grille beach', 'paulsboro', 'pedricktown', 'peerless park', 'pegram', 'pemberton', 'penllyn', 'penn valley', 'penndel', 'pennington', 'penns grove', 'pennsauken', 'pennsauken township', 'pennsaulen', 'pennsburg', 'pennsville', 'pennsville township', 'pennsylvania', 'perkasie', 'perkiomenville', 'petersburg', 'phila', 'philadelphia', 'philadelphia pa', 'philadelphila', 'philadephia', 'phoenixville', 'phonixville', 'picture rocks', 'pike creek', 'pilesgrove', 'pilgrim gardens', 'pilot sound area west portion', 'pine hill', 'pinecrest west park', 'pinellas', 'pinellas park', 'pineville', 'pipersville', 'pitman', 'pittsgrove', 'pittsgrove township', 'plainfield', 'plant city', 'pleasant township', 'pleasant view', 'plumsteadville', 'plymouth meeting', 'plymouth township', 'pontoon beach', 'port hueneme', 'port richey', 'pottsgrove', 'pottstown', 'primos', 'primos-secane', 'prospect park', 'quakertown', 'quinton', 'radnor', 'radnor township', 'real goleta', 'red hill', 'redingtn shor', 'redingtn shores', 'redington beach', 'redington shores', 'reno', 'reno ap', 'reno city', 'reno nevada', 'richboro', 'richmond heights', 'richwood', 'ridley', 'ridley park', 'ridley township', 'rillito', 'river ridge', 'river view', 'riveridge', 'riverside', 'riverton', 'riverview', 'rock hill', 'rockledge', 'roebling', 'rose valley', 'rosemont', 'roseville', 'rosewood heights', 'roslyn', 'roxana', 'roxborough', 'royersford', 'royford', 'runnemede', 'rural hill', 'rushland', 'ruskin', 's pasadena', 'safety  harbor', 'safety harbor', 'sahuarita', 'saint albert', 'saint ann', 'saint bernard', 'saint charles', 'saint davids', 'saint john', 'saint louis', 'saint louis ap', 'saint pete beach', 'saint peters', 'saint petersburg', 'saint petersburg beach', 'saint petersburg,', 'saint rose', 'saintt petersburg', 'saintã\\x82â\\xa0louis', 'salem', 'san anselmo', 'san antonio', 'sanatoga', 'santa barbara', 'santa barbara & ventura counties', 'santa barbara ap', 'santa barbara,', 'santa clara', 'santa rita', 'santa ynez', 'sappington', 'sarasota', 'sassamansville', 'sauget', 'schwenksville', 'scott afb', 'scott air force base', 'secane', 'seffner', 'sellersville', 'seminole', 'sewell', 'shade', 'shady hills', 'shamong', 'sharon hill', 'sherwood park', 'shiloh', 'shrewsbury', 'sicklerville', 'silverdale', 'skippack', 'skippack village', 'smithton', 'smyrna', 'solebury', 'somerdale', 'souderton', 'south cinnaminson', 'south county', 'south harrison township', 'south lake tahoe', 'south pasadena', 'south roxana', 'south tampa', 'south tucson', 'southampton', 'southampton township', 'southeast edmonton', 'southeastern', 'southport', 'southwest philadelphia', 'southwest tampa', 'spanish springs', 'sparks', 'sparks nv', 'speedway', 'spokane', 'spring city', 'spring hill', 'spring house', 'springfield', 'springhill', 'spruce grove', 'st  louis', 'st albert', 'st ann', 'st charles', 'st louis', 'st louis county', 'st louis downtown', 'st pete', 'st pete beach', 'st petersberg', 'st petersburg', 'st rose', 'st. albert', 'st. ann', 'st. charles', 'st. davids', 'st. loius', 'st. louis', 'st. pete', 'st. pete beach', 'st. peters', 'st. petersburg', 'st. rose', 'st.ann', 'st.louis', 'st.pete beach', 'st.petersburg', 'st.rose', 'staint albert', 'star', 'ste c', 'stead', 'stowe', 'strafford', 'stratford', 'stroudsburg', 'sturgeon couny', 'summerhaven', 'summerland', 'sumneytown', 'sun city', 'sun city center', 'sun valley', 'sunset hills', 'swansea', 'swarthmore', 'swedesboro', 'tabernacle', 'talleyville', 'tampa', 'tampa - north', 'tampa - south', 'tampa bay', 'tampa florida', 'tampa palms', 'tampa terrace', 'tampla', 'tarpon springs', 'telford', 'temple terr', 'temple terrace', 'terra ceia', 'terrytown', 'thonosassa', 'thonotosassa', 'thorndale', 'thornton', 'thorofare', 'tierra verde', 'tinicum', 'titusville', 'toughkenamon', 'town & country', 'town & county', \"town 'n' country\", 'town and country', 'town n country', 'trainer', 'trappe', 'treasure is', 'treasure island', 'tren', 'trenton', 'trevose', 'trinity', 'trolley square', 'trooper', 'troy', 'truckee', 'tucson', 'tucson, arizona', 'tullytown', 'turnersville', 'tuscon', 'tuson', 'twin oaks', 'twn n cntry', 'tylersport', 'unionville', 'university city', 'university park', 'upland', 'upper chichester', 'upper darby', 'upper darby pa', 'upper gwynedd', 'upper merion township', 'upper pittsgrove', 'upper southampton', 'upper southampton township', 'vail', 'valencia', 'valencia west', 'valley forge', 'valley park', 'valrico', 'vc highlands', 'ventura', 'verdi', 'view', 'villanova', 'vincentown', 'vineland', 'violet', 'virginia city', 'virtual', 'voorhees', 'voorhees township', 'w cherry hill', 'w.chester', 'waggaman', 'wallingford', 'wanamaker', 'warminster', 'warrington', 'warrington township', 'warson woods', 'warwick', 'washington', 'washington crossing', 'washington park', 'washington township', 'washington twp', 'washoe', 'washoe valley', 'waterford works', 'waterloo', 'wayne', 'wayne/radnor', 'webster groves', 'webster grvs', 'wenonah', 'wesley chapel', 'west  deptford', 'west alton', 'west berlin', 'west bradford township', 'west chester', 'west chester pa', 'west conshohocken', 'west deptford', 'west deptford townsh', 'west edmonton', 'west hill', 'west mount holly', 'west norriton', 'west philadelphia', 'west point', 'west trenton', 'westampton', 'westampton township', 'westchase', 'westfield', 'westmont', 'westmont - haddon towsship', 'westtown', 'westville', 'westwego', 'white house', 'whitehouse', 'whiteland', 'whites creek', 'whitestown', 'williamstown', 'willingboro', 'willingboro township', 'willow grove', 'wilmington', 'wilmington manor', 'wimauma', 'winslow', 'winslow township', 'wood river', 'woodbourne', 'woodbury', 'woodbury heights', 'woodlyn', 'woodson terrace', 'woodstown', 'woolwich township', 'woolwich twp', 'woolwich twp.', 'worcester', 'wrightstown', 'wyncote', 'wyndlake condominium', 'wyndmoor', 'wynnewood', 'yardley', 'yardley boro', 'ybor city', 'yeadon', 'yorklyn', 'zephryhills', 'zephyrhills', 'zieglersville', 'zieglerville', 'zionsville', 'ã¢â\\x80â\\x8bclayton', 'ã¢â\\x80â\\x8blargo', 'ã¢â\\x80â\\x8blithia']\n"
     ]
    }
   ],
   "source": [
    "print(sorted(df_businesses['city'].str.strip().str.lower().unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['business_id', 'name', 'address', 'city', 'state', 'postal_code',\n",
       "       'latitude', 'longitude', 'stars', 'review_count', 'is_open',\n",
       "       'attributes', 'categories', 'hours'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_businesses.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pns2l4eNsfO8kk83dixA6A</td>\n",
       "      <td>Abby Rappoport, LAC, CMQ</td>\n",
       "      <td>1616 Chapala St, Ste 2</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>CA</td>\n",
       "      <td>93101</td>\n",
       "      <td>34.426679</td>\n",
       "      <td>-119.711197</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>{'ByAppointmentOnly': 'True'}</td>\n",
       "      <td>Doctors, Traditional Chinese Medicine, Naturop...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mpf3x-BjTdTEA3yCZrAYPw</td>\n",
       "      <td>The UPS Store</td>\n",
       "      <td>87 Grasso Plaza Shopping Center</td>\n",
       "      <td>Affton</td>\n",
       "      <td>MO</td>\n",
       "      <td>63123</td>\n",
       "      <td>38.551126</td>\n",
       "      <td>-90.335695</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True'}</td>\n",
       "      <td>Shipping Centers, Local Services, Notaries, Ma...</td>\n",
       "      <td>{'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tUFrWirKiKi_TAnsVWINQQ</td>\n",
       "      <td>Target</td>\n",
       "      <td>5255 E Broadway Blvd</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85711</td>\n",
       "      <td>32.223236</td>\n",
       "      <td>-110.880452</td>\n",
       "      <td>3.5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>{'BikeParking': 'True', 'BusinessAcceptsCredit...</td>\n",
       "      <td>Department Stores, Shopping, Fashion, Home &amp; G...</td>\n",
       "      <td>{'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>935 Race St</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19107</td>\n",
       "      <td>39.955505</td>\n",
       "      <td>-75.155564</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsDelivery': 'False', 'OutdoorSeati...</td>\n",
       "      <td>Restaurants, Food, Bubble Tea, Coffee &amp; Tea, B...</td>\n",
       "      <td>{'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mWMc6_wTdE0EUBKIGXDVfA</td>\n",
       "      <td>Perkiomen Valley Brewery</td>\n",
       "      <td>101 Walnut St</td>\n",
       "      <td>Green Lane</td>\n",
       "      <td>PA</td>\n",
       "      <td>18054</td>\n",
       "      <td>40.338183</td>\n",
       "      <td>-75.471659</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True', 'Wheelc...</td>\n",
       "      <td>Brewpubs, Breweries, Food</td>\n",
       "      <td>{'Wednesday': '14:0-22:0', 'Thursday': '16:0-2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                      name  \\\n",
       "0  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ   \n",
       "1  mpf3x-BjTdTEA3yCZrAYPw             The UPS Store   \n",
       "2  tUFrWirKiKi_TAnsVWINQQ                    Target   \n",
       "3  MTSW4McQd7CbVtyjqoe9mw        St Honore Pastries   \n",
       "4  mWMc6_wTdE0EUBKIGXDVfA  Perkiomen Valley Brewery   \n",
       "\n",
       "                           address           city state postal_code  \\\n",
       "0           1616 Chapala St, Ste 2  Santa Barbara    CA       93101   \n",
       "1  87 Grasso Plaza Shopping Center         Affton    MO       63123   \n",
       "2             5255 E Broadway Blvd         Tucson    AZ       85711   \n",
       "3                      935 Race St   Philadelphia    PA       19107   \n",
       "4                    101 Walnut St     Green Lane    PA       18054   \n",
       "\n",
       "    latitude   longitude  stars  review_count  is_open  \\\n",
       "0  34.426679 -119.711197    5.0             7        0   \n",
       "1  38.551126  -90.335695    3.0            15        1   \n",
       "2  32.223236 -110.880452    3.5            22        0   \n",
       "3  39.955505  -75.155564    4.0            80        1   \n",
       "4  40.338183  -75.471659    4.5            13        1   \n",
       "\n",
       "                                          attributes  \\\n",
       "0                      {'ByAppointmentOnly': 'True'}   \n",
       "1             {'BusinessAcceptsCreditCards': 'True'}   \n",
       "2  {'BikeParking': 'True', 'BusinessAcceptsCredit...   \n",
       "3  {'RestaurantsDelivery': 'False', 'OutdoorSeati...   \n",
       "4  {'BusinessAcceptsCreditCards': 'True', 'Wheelc...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Doctors, Traditional Chinese Medicine, Naturop...   \n",
       "1  Shipping Centers, Local Services, Notaries, Ma...   \n",
       "2  Department Stores, Shopping, Fashion, Home & G...   \n",
       "3  Restaurants, Food, Bubble Tea, Coffee & Tea, B...   \n",
       "4                          Brewpubs, Breweries, Food   \n",
       "\n",
       "                                               hours  \n",
       "0                                                NaN  \n",
       "1  {'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...  \n",
       "2  {'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...  \n",
       "3  {'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...  \n",
       "4  {'Wednesday': '14:0-22:0', 'Thursday': '16:0-2...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_businesses.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1: Best Restaurants in Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         name  stars  review_count  \\\n",
      "69859                   Tortilleria San Roman    5.0           219   \n",
      "85917                    Miss Rachel's Pantry    5.0           119   \n",
      "79657                         El Rancho Viejo    5.0           110   \n",
      "25331                       Circles + Squares    5.0           103   \n",
      "5993   Mom Mom's Kitchen and Polish Food Cart    5.0            91   \n",
      "\n",
      "                                              categories  \n",
      "69859  Convenience Stores, Italian, Specialty Food, M...  \n",
      "85917  Arts & Crafts, Food, Shopping, Food Delivery S...  \n",
      "79657                               Restaurants, Mexican  \n",
      "25331                                 Restaurants, Pizza  \n",
      "5993   Food, Polish, Food Trucks, Street Vendors, Res...  \n"
     ]
    }
   ],
   "source": [
    "philadelphia_restaurants = df_businesses[(df_businesses['city'].str.strip().str.lower() == 'philadelphia') & df_businesses['categories'].str.contains('Restaurants', case=False, na=False)]\n",
    "top_philadelphia_restaurants = philadelphia_restaurants.sort_values(by=['stars', 'review_count', 'name'], ascending=[False, False, True]).head(5)\n",
    "print(top_philadelphia_restaurants[['name', 'stars', 'review_count', 'categories']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2: Best Chinese Restaurants in Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           name  stars  review_count  \\\n",
      "41818  Far East Chinese Cuisine    5.0            28   \n",
      "67395             House of Chen    5.0            10   \n",
      "23052             Peking Garden    5.0             9   \n",
      "63522              Paradise Inn    5.0             8   \n",
      "12494               Jade Palace    5.0             6   \n",
      "\n",
      "                                         categories  \n",
      "41818               Cantonese, Chinese, Restaurants  \n",
      "67395                          Restaurants, Chinese  \n",
      "23052  American (Traditional), Chinese, Restaurants  \n",
      "63522                          Chinese, Restaurants  \n",
      "12494                          Restaurants, Chinese  \n"
     ]
    }
   ],
   "source": [
    "chinese_restaurants_philadelphia = philadelphia_restaurants[philadelphia_restaurants['categories'].str.contains('Chinese', case=False, na=False)]\n",
    "top_chinese_restaurants_philadelphia = chinese_restaurants_philadelphia.sort_values(by=['stars', 'review_count', 'name'], ascending=[False, False, True]).head(5)\n",
    "print(top_chinese_restaurants_philadelphia[['name', 'stars', 'review_count', 'categories']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3: Pubs in Philadelphia that are Wheelchair Accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            name  stars  review_count  \\\n",
      "94471                  Bar Hygge    4.5           387   \n",
      "53651   Glory Beer Bar & Kitchen    4.5           203   \n",
      "79730  Love City Brewing Company    4.5           162   \n",
      "1106            Chase's Hop Shop    4.5           116   \n",
      "78757     Original 13 Ciderworks    4.5            65   \n",
      "\n",
      "                                              categories  \n",
      "94471  Food, Restaurants, Breweries, Comfort Food, Br...  \n",
      "53651  American (New), Local Flavor, Bars, Restaurant...  \n",
      "79730  Brewpubs, Breweries, Nightlife, Bars, Food, Ba...  \n",
      "1106   Chicken Wings, Nightlife, Bars, Delis, Food, B...  \n",
      "78757  American (Traditional), Food, Restaurants, Bar...  \n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import pandas as pd\n",
    "import ast  # To safely evaluate a string containing a Python literal or container display\n",
    "\n",
    "# Assume df_businesses is your DataFrame\n",
    "# Let's define a function to parse the 'attributes' column and check for wheelchair accessibility\n",
    "def parse_wheelchair_accessible(attributes_str):\n",
    "    try:\n",
    "        # Safely evaluate the string as a Python dictionary\n",
    "        attributes_dict = ast.literal_eval(attributes_str)\n",
    "        # Check if 'WheelchairAccessible' is true\n",
    "        return attributes_dict.get('WheelchairAccessible', 'False') == 'True'\n",
    "    except ValueError:  # Includes handling malformed strings\n",
    "        return False\n",
    "\n",
    "# Create a copy to avoid the SettingWithCopyWarning when creating a new column\n",
    "philadelphia_pubs = df_businesses[\n",
    "    (df_businesses['city'].str.strip().str.lower() == 'philadelphia') &\n",
    "    df_businesses['categories'].str.contains('Pubs', case=False, na=False)\n",
    "].copy()\n",
    "\n",
    "# Apply the function to create a new column for wheelchair accessibility\n",
    "philadelphia_pubs.loc[:, 'is_wheelchair_accessible'] = philadelphia_pubs['attributes'].apply(parse_wheelchair_accessible)\n",
    "\n",
    "# Filter for pubs that are wheelchair accessible\n",
    "wheelchair_accessible_pubs = philadelphia_pubs[philadelphia_pubs['is_wheelchair_accessible']]\n",
    "\n",
    "# Sort and select the top 5 based on 'stars', 'review_count', and 'name'\n",
    "top_accessible_pubs = wheelchair_accessible_pubs.sort_values(by=['stars', 'review_count', 'name'], ascending=[False, False, True]).head(5)\n",
    "\n",
    "print(top_accessible_pubs[['name', 'stars', 'review_count', 'categories']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 4: Business Hours for \"DeSandro on Main\" in Philadelphia for Friday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The business hours for 'DeSandro on Main' on Friday are: 5:00 PM - 12:30 AM\n"
     ]
    }
   ],
   "source": [
    "def format_hours(hour_str):\n",
    "    open_time, close_time = hour_str.split('-')\n",
    "    open_time_formatted = pd.to_datetime(open_time, format='%H:%M').strftime('%I:%M %p').lstrip('0')\n",
    "    close_time_formatted = pd.to_datetime(close_time, format='%H:%M').strftime('%I:%M %p').lstrip('0')\n",
    "    return f\"{open_time_formatted} - {close_time_formatted}\"\n",
    "\n",
    "# This function parses the 'hours' attribute for the given day\n",
    "def parse_hours(hours_str, day):\n",
    "    if pd.isna(hours_str):\n",
    "        return 'Not available'  # Return this if the 'hours' data is missing\n",
    "    try:\n",
    "        # Replace single quotes with double quotes for JSON\n",
    "        hours_dict = json.loads(hours_str.replace(\"'\", \"\\\"\"))\n",
    "        # Check if the business hours for the specified day are available\n",
    "        hours_for_day = hours_dict.get(day, 'Not available')\n",
    "        if hours_for_day != 'Not available':\n",
    "            # Format hours to a more readable format\n",
    "            return format_hours(hours_for_day)\n",
    "        return hours_for_day\n",
    "    except json.JSONDecodeError:\n",
    "        return 'Not available'\n",
    "\n",
    "# Now, let's apply this to 'DeSandro on Main' for Friday's hours\n",
    "# Assuming the DataFrame df_businesses is already loaded\n",
    "\n",
    "# Find 'DeSandro on Main' in Philadelphia\n",
    "desandro_on_main = df_businesses[\n",
    "    (df_businesses['city'].str.strip().str.lower() == 'philadelphia') &\n",
    "    (df_businesses['name'].str.strip().str.lower() == 'desandro on main')\n",
    "]\n",
    "\n",
    "# Assuming there is only one such business\n",
    "if not desandro_on_main.empty:\n",
    "    friday_hours = parse_hours(desandro_on_main.iloc[0]['hours'], 'Friday')\n",
    "    print(f\"The business hours for 'DeSandro on Main' on Friday are: {friday_hours}\")\n",
    "else:\n",
    "    print(\"'DeSandro on Main' not found in Philadelphia.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 5: List of 5 Pubs Near a Given Landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 pubs near the landmark:\n",
      "                               name  distance  \\\n",
      "68235  Cooperage Wine & Whiskey Bar  0.234054   \n",
      "41697      Six Feet Under Gastropub  0.330113   \n",
      "73643        Common Wealth Old City  0.347829   \n",
      "61025          Craftsman Row Saloon  0.349899   \n",
      "33988            National Mechanics  0.366175   \n",
      "\n",
      "                                              categories  \n",
      "68235  Nightlife, Food, Southern, Beer, Wine & Spirit...  \n",
      "41697  Breakfast & Brunch, Nightlife, Restaurants, Ba...  \n",
      "73643   Gastropubs, Restaurants, American (New), Seafood  \n",
      "61025                              Pubs, Nightlife, Bars  \n",
      "33988  Pubs, Food, Breakfast & Brunch, Dance Clubs, B...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "# Sample data loading, replace this with your actual data loading code\n",
    "# df_businesses = pd.read_csv('your_dataset.csv')\n",
    "\n",
    "# Haversine formula to calculate the distance between two points on the Earth\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    # Convert decimal degrees to radians\n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    r = 6371  # Radius of Earth in kilometers\n",
    "    return c * r\n",
    "\n",
    "# Assuming we have the coordinates for a landmark (e.g., the Liberty Bell in Philadelphia)\n",
    "landmark_lat, landmark_lon = 39.949610, -75.150282  # Liberty Bell coordinates\n",
    "\n",
    "# Filter for pubs in Philadelphia\n",
    "philadelphia_pubs = df_businesses[\n",
    "    df_businesses['categories'].str.contains('Pubs', case=False, na=False)\n",
    "].copy()\n",
    "\n",
    "# If no pubs are found, return a message\n",
    "if philadelphia_pubs.empty:\n",
    "    print(\"No pubs found.\")\n",
    "else:\n",
    "    # Calculate distance for each pub from the landmark and add it as a new column\n",
    "    philadelphia_pubs['distance'] = philadelphia_pubs.apply(\n",
    "        lambda row: haversine(landmark_lon, landmark_lat, row['longitude'], row['latitude']), \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Sort by distance and select the top 5\n",
    "    top_nearby_pubs = philadelphia_pubs.sort_values(by='distance').head(5)\n",
    "\n",
    "    print(\"Top 5 pubs near the landmark:\")\n",
    "    print(top_nearby_pubs[['name', 'distance', 'categories']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"width:100%;\"><div style=\"position:relative;width:100%;height:0;padding-bottom:60%;\"><span style=\"color:#565656\">Make this Notebook Trusted to load map: File -> Trust Notebook</span><iframe srcdoc=\"&lt;!DOCTYPE html&gt;\n",
       "&lt;html&gt;\n",
       "&lt;head&gt;\n",
       "    \n",
       "    &lt;meta http-equiv=&quot;content-type&quot; content=&quot;text/html; charset=UTF-8&quot; /&gt;\n",
       "    \n",
       "        &lt;script&gt;\n",
       "            L_NO_TOUCH = false;\n",
       "            L_DISABLE_3D = false;\n",
       "        &lt;/script&gt;\n",
       "    \n",
       "    &lt;style&gt;html, body {width: 100%;height: 100%;margin: 0;padding: 0;}&lt;/style&gt;\n",
       "    &lt;style&gt;#map {position:absolute;top:0;bottom:0;right:0;left:0;}&lt;/style&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://code.jquery.com/jquery-3.7.1.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/js/bootstrap.bundle.min.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js&quot;&gt;&lt;/script&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/leaflet@1.9.3/dist/leaflet.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/bootstrap@5.2.2/dist/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://netdna.bootstrapcdn.com/bootstrap/3.0.0/css/bootstrap.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.2.0/css/all.min.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css&quot;/&gt;\n",
       "    &lt;link rel=&quot;stylesheet&quot; href=&quot;https://cdn.jsdelivr.net/gh/python-visualization/folium/folium/templates/leaflet.awesome.rotate.min.css&quot;/&gt;\n",
       "    \n",
       "            &lt;meta name=&quot;viewport&quot; content=&quot;width=device-width,\n",
       "                initial-scale=1.0, maximum-scale=1.0, user-scalable=no&quot; /&gt;\n",
       "            &lt;style&gt;\n",
       "                #map_2d02a09b3c25ae5e044d283905a3f517 {\n",
       "                    position: relative;\n",
       "                    width: 100.0%;\n",
       "                    height: 100.0%;\n",
       "                    left: 0.0%;\n",
       "                    top: 0.0%;\n",
       "                }\n",
       "                .leaflet-container { font-size: 1rem; }\n",
       "            &lt;/style&gt;\n",
       "        \n",
       "&lt;/head&gt;\n",
       "&lt;body&gt;\n",
       "    \n",
       "    \n",
       "            &lt;div class=&quot;folium-map&quot; id=&quot;map_2d02a09b3c25ae5e044d283905a3f517&quot; &gt;&lt;/div&gt;\n",
       "        \n",
       "&lt;/body&gt;\n",
       "&lt;script&gt;\n",
       "    \n",
       "    \n",
       "            var map_2d02a09b3c25ae5e044d283905a3f517 = L.map(\n",
       "                &quot;map_2d02a09b3c25ae5e044d283905a3f517&quot;,\n",
       "                {\n",
       "                    center: [47.6205, -122.3493],\n",
       "                    crs: L.CRS.EPSG3857,\n",
       "                    zoom: 14,\n",
       "                    zoomControl: true,\n",
       "                    preferCanvas: false,\n",
       "                }\n",
       "            );\n",
       "\n",
       "            \n",
       "\n",
       "        \n",
       "    \n",
       "            var tile_layer_0b6ca46e6f9f7a71f93e5b424a12dd70 = L.tileLayer(\n",
       "                &quot;https://tile.openstreetmap.org/{z}/{x}/{y}.png&quot;,\n",
       "                {&quot;attribution&quot;: &quot;\\u0026copy; \\u003ca href=\\&quot;https://www.openstreetmap.org/copyright\\&quot;\\u003eOpenStreetMap\\u003c/a\\u003e contributors&quot;, &quot;detectRetina&quot;: false, &quot;maxNativeZoom&quot;: 19, &quot;maxZoom&quot;: 19, &quot;minZoom&quot;: 0, &quot;noWrap&quot;: false, &quot;opacity&quot;: 1, &quot;subdomains&quot;: &quot;abc&quot;, &quot;tms&quot;: false}\n",
       "            );\n",
       "        \n",
       "    \n",
       "            tile_layer_0b6ca46e6f9f7a71f93e5b424a12dd70.addTo(map_2d02a09b3c25ae5e044d283905a3f517);\n",
       "        \n",
       "    \n",
       "            var marker_c91e1a0d5e46d9b388595df96e696be3 = L.marker(\n",
       "                [47.6205, -122.3493],\n",
       "                {}\n",
       "            ).addTo(map_2d02a09b3c25ae5e044d283905a3f517);\n",
       "        \n",
       "    \n",
       "        var popup_e9acdd7affe56a761aee2e03c56b53d3 = L.popup({&quot;maxWidth&quot;: &quot;100%&quot;});\n",
       "\n",
       "        \n",
       "            \n",
       "                var html_031ad6ad28694ade4ca0495cfa71dc5a = $(`&lt;div id=&quot;html_031ad6ad28694ade4ca0495cfa71dc5a&quot; style=&quot;width: 100.0%; height: 100.0%;&quot;&gt;Space Needle, Seattle&lt;/div&gt;`)[0];\n",
       "                popup_e9acdd7affe56a761aee2e03c56b53d3.setContent(html_031ad6ad28694ade4ca0495cfa71dc5a);\n",
       "            \n",
       "        \n",
       "\n",
       "        marker_c91e1a0d5e46d9b388595df96e696be3.bindPopup(popup_e9acdd7affe56a761aee2e03c56b53d3)\n",
       "        ;\n",
       "\n",
       "        \n",
       "    \n",
       "    \n",
       "            marker_c91e1a0d5e46d9b388595df96e696be3.bindTooltip(\n",
       "                `&lt;div&gt;\n",
       "                     Space Needle, Seattle\n",
       "                 &lt;/div&gt;`,\n",
       "                {&quot;sticky&quot;: true}\n",
       "            );\n",
       "        \n",
       "&lt;/script&gt;\n",
       "&lt;/html&gt;\" style=\"position:absolute;width:100%;height:100%;left:0;top:0;border:none !important;\" allowfullscreen webkitallowfullscreen mozallowfullscreen></iframe></div></div>"
      ],
      "text/plain": [
       "<folium.folium.Map at 0x7fd94cc3e6d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "\n",
    "# Space Needle coordinates\n",
    "landmark_lat, landmark_lon = 47.6205, -122.3493\n",
    "landmark_name = \"Space Needle, Seattle\"\n",
    "\n",
    "# Function to calculate distance between two points\n",
    "def calculate_distance(lat1, lon1, lat2, lon2):\n",
    "    # Haversine formula to calculate distance between two lat/lon points\n",
    "    from math import radians, cos, sin, asin, sqrt\n",
    "    R = 6371  # Earth radius in kilometers\n",
    "    lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    distance = R * c\n",
    "    return distance\n",
    "\n",
    "# Filter for pubs in Seattle\n",
    "seattle_pubs = df_businesses[(df_businesses['city'].str.strip().str.lower() == 'seattle') &\n",
    "                             df_businesses['categories'].str.contains('Pubs', case=False, na=False)]\n",
    "\n",
    "# Calculate distances from the landmark\n",
    "seattle_pubs['distance'] = seattle_pubs.apply(\n",
    "    lambda row: calculate_distance(landmark_lat, landmark_lon, row['latitude'], row['longitude']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Sort by distance and get the top 5\n",
    "nearest_pubs = seattle_pubs.sort_values('distance').head(5)\n",
    "\n",
    "# Create a map centered around the landmark\n",
    "map_ = folium.Map(location=[landmark_lat, landmark_lon], zoom_start=14)\n",
    "\n",
    "# Add a marker for the landmark\n",
    "folium.Marker([landmark_lat, landmark_lon], tooltip=landmark_name, popup=landmark_name).add_to(map_)\n",
    "\n",
    "# Add markers for the pubs\n",
    "for idx, row in nearest_pubs.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        popup=f\"{row['name']}, {row['stars']} stars, {row['review_count']} reviews\",\n",
    "        icon=folium.Icon(color='blue', icon='glyphicon-glass')\n",
    "    ).add_to(map_)\n",
    "\n",
    "# Display the map\n",
    "map_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Recommender System using Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['best', 'pho', 'santa', 'barbara', 'county', 'staff', 'great', 'drive', '3540', 'minutes', 'pho', 'would', 'drive', 'double', 'seriously', 'tho', 'pho', 'withdrawals', 'thanks', 'phamous']\n",
      "['place', 'awesome', 'right', 'walk', 'ur', 'overwhelmed', 'many', 'options', 'available', 'hard', 'choose', 'guy', 'helped', 'us', 'friendly', 'made', 'polite', 'conversation', 'lets', 'talk', 'actual', 'gelato', 'good', 'quality', 'amazing', 'especially', 'liked', 'lotus', 'cookie', 'mango', 'outside', 'place', 'hopping', 'makes', 'feel', 'like', 'ur', 'somewhere', 'tucson', 'come']\n"
     ]
    }
   ],
   "source": [
    "df_train['tokens'] = df_train['text'].apply(tokenize_text)\n",
    "\n",
    "# Check the tokenized text for the first and twelfth entries\n",
    "print(df_train['tokens'].iloc[0])\n",
    "print(df_train['tokens'].iloc[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that all vectors in embeddings_dict are of the same length\n",
    "# This step depends on how you have created embeddings_dict\n",
    "\n",
    "embeddings_dict = load_glove(50)\n",
    "\n",
    "for word, vec in embeddings_dict.items():\n",
    "    if len(vec) != 50:\n",
    "        raise ValueError(f\"Vector length for word '{word}' is not 50\")\n",
    "\n",
    "def create_embeddings(df_grouped, embeddings_dict):\n",
    "    embeddings = {}\n",
    "    for id, group in df_grouped:\n",
    "        all_tokens = sum(group['tokens'].tolist(), [])\n",
    "        vectors = np.array([embeddings_dict.get(token, np.zeros(50, dtype=\"float32\")) for token in all_tokens])\n",
    "        # Check if all vectors are indeed NumPy arrays of the same shape\n",
    "        if not all(isinstance(v, np.ndarray) and v.shape == (50,) for v in vectors):\n",
    "            raise ValueError(\"Not all vectors are NumPy arrays of shape (50,)\")\n",
    "        embeddings[id] = np.mean(vectors, axis=0) if vectors.size else np.zeros(50, dtype=\"float32\")\n",
    "    return embeddings\n",
    "\n",
    "# Group by user_id and business_id\n",
    "grouped_by_users = df_train.groupby('user_id')\n",
    "grouped_by_businesses = df_train.groupby('business_id')\n",
    "\n",
    "# Create embeddings\n",
    "user_embeddings = create_embeddings(grouped_by_users, embeddings_dict)\n",
    "business_embeddings = create_embeddings(grouped_by_businesses, embeddings_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.164516949912093\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Predict ratings and calculate RMSE\n",
    "def predict_rating(user_id, business_id, user_embeddings, business_embeddings):\n",
    "    user_vector = user_embeddings.get(user_id, np.zeros(50, dtype=\"float32\"))\n",
    "    business_vector = business_embeddings.get(business_id, np.zeros(50, dtype=\"float32\"))\n",
    "    return np.dot(user_vector, business_vector)\n",
    "\n",
    "# Predict ratings for the test set\n",
    "df_test['predicted_stars'] = df_test.apply(lambda x: predict_rating(x['user_id'], x['business_id'], user_embeddings, business_embeddings), axis=1)\n",
    "\n",
    "# Calculate RMSE\n",
    "rmse = np.sqrt(((df_test['stars'] - df_test['predicted_stars']) ** 2).mean())\n",
    "print(f\"RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation RMSE with ML: 1.1005369679756283\n",
      "Test RMSE with ML: 1.3972470156677497\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Prepare data for ML model\n",
    "X = []\n",
    "y = []\n",
    "for _, row in df_train.iterrows():\n",
    "    user_vec = user_embeddings.get(row['user_id'], np.zeros(50))\n",
    "    business_vec = business_embeddings.get(row['business_id'], np.zeros(50))\n",
    "    # Element-wise multiplication of user and business vectors\n",
    "    X.append(user_vec * business_vec)\n",
    "    y.append(row['stars'])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Split the training data for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a regressor\n",
    "regressor = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set and calculate RMSE\n",
    "val_predictions = regressor.predict(X_val)\n",
    "rmse_val = np.sqrt(mean_squared_error(y_val, val_predictions))\n",
    "print(f\"Validation RMSE with ML: {rmse_val}\")\n",
    "\n",
    "# Prepare test data and make predictions\n",
    "X_test = []\n",
    "for _, row in df_test.iterrows():\n",
    "    user_vec = user_embeddings.get(row['user_id'], np.zeros(50))\n",
    "    business_vec = business_embeddings.get(row['business_id'], np.zeros(50))\n",
    "    X_test.append(user_vec * business_vec)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "test_predictions = regressor.predict(X_test)\n",
    "\n",
    "# Calculate RMSE for test predictions\n",
    "rmse_test = np.sqrt(mean_squared_error(df_test['stars'], test_predictions))\n",
    "print(f\"Test RMSE with ML: {rmse_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK 3: Item-based Collaborative Recommendation using Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_businesses(target_business_name, city, embeddings_dict, df_businesses, top_n=5):\n",
    "    # Find the business ID for the target business\n",
    "    target_business = df_businesses[(df_businesses['name'].str.lower() == target_business_name.lower()) & (df_businesses['city'].str.lower() == city.lower())]\n",
    "    if target_business.empty:\n",
    "        return f\"No business found with name {target_business_name} in {city}\"\n",
    "\n",
    "    target_business_id = target_business.iloc[0]['business_id']\n",
    "    target_embedding = embeddings_dict.get(target_business_id)\n",
    "    if target_embedding is None:\n",
    "        return f\"No embedding found for {target_business_name}\"\n",
    "\n",
    "    city_businesses = df_businesses[df_businesses['city'].str.strip().str.lower() == city.lower()]\n",
    "    similarities = []\n",
    "\n",
    "    for _, row in city_businesses.iterrows():\n",
    "        business_embedding = embeddings_dict.get(row['business_id'])\n",
    "        if business_embedding is not None:\n",
    "            cosine_similarity = np.dot(target_embedding, business_embedding) / (np.linalg.norm(target_embedding) * np.linalg.norm(business_embedding))\n",
    "            similarities.append((row['name'], row['stars'], row['categories'], cosine_similarity))\n",
    "\n",
    "    # Sort by similarity score in descending order\n",
    "    similarities.sort(key=lambda x: x[3], reverse=True)\n",
    "\n",
    "    # Return the top n similar businesses\n",
    "    return similarities[:top_n]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1: Similar Auto Body Shops to 'Iron Horse Auto Body' in Santa Barbara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Auto Body Shops to 'Iron Horse Auto Body' in Santa Barbara:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iron Horse Auto Body</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Towing, Automotive, Body Shops</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Top Shop Automotive</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Auto Parts &amp; Supplies, Wheel &amp; Rim Repair, Oil...</td>\n",
       "      <td>0.991074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Movegreen</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Local Services, Shopping, Home Services, Mover...</td>\n",
       "      <td>0.988810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sears Auto Center</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Auto Repair, Oil Change Stations, Automotive, ...</td>\n",
       "      <td>0.987441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Granny's Garage</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Auto Repair, Automotive</td>\n",
       "      <td>0.985977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name  Stars  \\\n",
       "0  Iron Horse Auto Body    4.5   \n",
       "1   Top Shop Automotive    4.0   \n",
       "2             Movegreen    4.5   \n",
       "3     Sears Auto Center    2.5   \n",
       "4       Granny's Garage    4.5   \n",
       "\n",
       "                                          Categories  Similarity  \n",
       "0                     Towing, Automotive, Body Shops    1.000000  \n",
       "1  Auto Parts & Supplies, Wheel & Rim Repair, Oil...    0.991074  \n",
       "2  Local Services, Shopping, Home Services, Mover...    0.988810  \n",
       "3  Auto Repair, Oil Change Stations, Automotive, ...    0.987441  \n",
       "4                            Auto Repair, Automotive    0.985977  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_auto_body_shops = find_similar_businesses(\"Iron Horse Auto Body\", 'santa barbara', business_embeddings, df_businesses)\n",
    "\n",
    "# Create a list of dictionaries\n",
    "data = [{'Name': name, 'Stars': stars, 'Categories': categories, 'Similarity': similarity} for name, stars, categories, similarity in similar_auto_body_shops]\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "df_similar_auto_body_shops = pd.DataFrame(data)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(\"Similar Auto Body Shops to 'Iron Horse Auto Body' in Santa Barbara:\")\n",
    "df_similar_auto_body_shops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2: Similar Salons to 'Kevin's Hair Salon' in Philadelphia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Salons to 'Kevin's Hair Salon' in Philadelphia:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kevin's Hair Salon</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Beauty &amp; Spas, Nail Salons, Hair Salons, Hair ...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Francis The Duke Barber Co.</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Barbers, Men's Clothing, Beauty &amp; Spas, Shoppi...</td>\n",
       "      <td>0.986104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Andre Richard Salon</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Hair Stylists, Barbers, Bridal, Beauty &amp; Spas,...</td>\n",
       "      <td>0.985781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deluxe Hair Salon</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Beauty &amp; Spas, Hair Salons</td>\n",
       "      <td>0.983984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Apsara Cutting Edge</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Hair Salons, Beauty &amp; Spas</td>\n",
       "      <td>0.983732</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Name  Stars  \\\n",
       "0           Kevin's Hair Salon    3.0   \n",
       "1  Francis The Duke Barber Co.    4.5   \n",
       "2          Andre Richard Salon    4.5   \n",
       "3            Deluxe Hair Salon    4.5   \n",
       "4          Apsara Cutting Edge    4.5   \n",
       "\n",
       "                                          Categories  Similarity  \n",
       "0  Beauty & Spas, Nail Salons, Hair Salons, Hair ...    1.000000  \n",
       "1  Barbers, Men's Clothing, Beauty & Spas, Shoppi...    0.986104  \n",
       "2  Hair Stylists, Barbers, Bridal, Beauty & Spas,...    0.985781  \n",
       "3                         Beauty & Spas, Hair Salons    0.983984  \n",
       "4                         Hair Salons, Beauty & Spas    0.983732  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_salons = find_similar_businesses(\"Kevin's Hair Salon\", 'Philadelphia', business_embeddings, df_businesses)\n",
    "similar_salons_df = pd.DataFrame(similar_salons, columns=['Name', 'Stars', 'Categories', 'Similarity'])\n",
    "\n",
    "print(\"Similar Salons to 'Kevin's Hair Salon' in Philadelphia:\")\n",
    "similar_salons_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3: Similar Event Planning to 'Two Rivers Campground' in Nashville"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Event Planning to 'Two Rivers Campground' in Nashville:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Two Rivers Campground</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Hotels &amp; Travel, Event Planning &amp; Services, Ca...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gaylord Opryland Resort &amp; Convention Center</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Venues &amp; Event Spaces, Performing Arts, Arts &amp;...</td>\n",
       "      <td>0.994396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La Quinta Inn by Wyndham Nashville South</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Hotels, Hotels &amp; Travel, Event Planning &amp; Serv...</td>\n",
       "      <td>0.991707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Holiday Inn Nashville-Vanderbilt</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Fashion, Event Planning &amp; Services, Venues &amp; E...</td>\n",
       "      <td>0.991254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Courtyard by Marriott Nashville Downtown</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Event Planning &amp; Services, Hotels &amp; Travel, Ve...</td>\n",
       "      <td>0.990129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Name  Stars  \\\n",
       "0                        Two Rivers Campground    3.5   \n",
       "1  Gaylord Opryland Resort & Convention Center    3.0   \n",
       "2     La Quinta Inn by Wyndham Nashville South    2.0   \n",
       "3             Holiday Inn Nashville-Vanderbilt    3.5   \n",
       "4     Courtyard by Marriott Nashville Downtown    3.0   \n",
       "\n",
       "                                          Categories  Similarity  \n",
       "0  Hotels & Travel, Event Planning & Services, Ca...    1.000000  \n",
       "1  Venues & Event Spaces, Performing Arts, Arts &...    0.994396  \n",
       "2  Hotels, Hotels & Travel, Event Planning & Serv...    0.991707  \n",
       "3  Fashion, Event Planning & Services, Venues & E...    0.991254  \n",
       "4  Event Planning & Services, Hotels & Travel, Ve...    0.990129  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_planning = find_similar_businesses(\"Two Rivers Campground\", 'Nashville', business_embeddings, df_businesses)\n",
    "similar_campgrounds_df = pd.DataFrame(similar_planning, columns=['Name', 'Stars', 'Categories', 'Similarity'])\n",
    "\n",
    "print(\"Similar Event Planning to 'Two Rivers Campground' in Nashville:\")\n",
    "similar_campgrounds_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 4: Similar Restaurants to 'Sapporo Sushi' in Edmonton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Restaurants to 'Sapporo Sushi' in Edmonton:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sapporo Sushi</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Japanese, Sushi Bars, Restaurants</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hudsons Canada's Pub</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Chicken Wings, Canadian (New), Restaurants, Sp...</td>\n",
       "      <td>0.995253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pho Hoan Pasteur</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Vietnamese, Restaurants</td>\n",
       "      <td>0.992913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Red Piano</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Jazz &amp; Blues, Lounges, Restaurants, Nightlife,...</td>\n",
       "      <td>0.992860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PrimeTime Donair</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Donairs, Specialty Food, Ethnic Food, Food, Im...</td>\n",
       "      <td>0.992743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Name  Stars  \\\n",
       "0         Sapporo Sushi    2.5   \n",
       "1  Hudsons Canada's Pub    3.5   \n",
       "2      Pho Hoan Pasteur    3.5   \n",
       "3         The Red Piano    3.0   \n",
       "4      PrimeTime Donair    3.5   \n",
       "\n",
       "                                          Categories  Similarity  \n",
       "0                  Japanese, Sushi Bars, Restaurants    1.000000  \n",
       "1  Chicken Wings, Canadian (New), Restaurants, Sp...    0.995253  \n",
       "2                            Vietnamese, Restaurants    0.992913  \n",
       "3  Jazz & Blues, Lounges, Restaurants, Nightlife,...    0.992860  \n",
       "4  Donairs, Specialty Food, Ethnic Food, Food, Im...    0.992743  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find similar restaurants to a specific restaurant\n",
    "similar_restaurants = find_similar_businesses(\"Sapporo Sushi\", 'Edmonton', business_embeddings, df_businesses)\n",
    "\n",
    "# Create a DataFrame from the similar restaurants\n",
    "similar_restaurants_df = pd.DataFrame(similar_restaurants, columns=['Name', 'Stars', 'Categories', 'Similarity'])\n",
    "\n",
    "# Print the similar restaurants\n",
    "print(\"Similar Restaurants to 'Sapporo Sushi' in Edmonton:\")\n",
    "similar_restaurants_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 5: Similar Entertainment Venues to 'Du Bowl Lanes' in Saint Louis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar Entertainment Venues to 'Du Bowl Lanes' in Saint Louis:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Categories</th>\n",
       "      <th>Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Du Bowl Lanes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Bars, Bowling, Cocktail Bars, Nightlife, Recre...</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nadine's Gin Joint</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Restaurants, Breakfast &amp; Brunch, Bars, Diners,...</td>\n",
       "      <td>0.975629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rue 13</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Dance Clubs, Sushi Bars, Restaurants, Bars, Ni...</td>\n",
       "      <td>0.975572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seven Zero Eight</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Arts &amp; Entertainment, Nightlife, Comfort Food,...</td>\n",
       "      <td>0.973524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jack Patrick's Bar &amp; Grill</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Sports Bars, Pubs, American (Traditional), Res...</td>\n",
       "      <td>0.973021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name  Stars  \\\n",
       "0               Du Bowl Lanes    5.0   \n",
       "1          Nadine's Gin Joint    3.5   \n",
       "2                      Rue 13    3.5   \n",
       "3            Seven Zero Eight    2.0   \n",
       "4  Jack Patrick's Bar & Grill    4.0   \n",
       "\n",
       "                                          Categories  Similarity  \n",
       "0  Bars, Bowling, Cocktail Bars, Nightlife, Recre...    1.000000  \n",
       "1  Restaurants, Breakfast & Brunch, Bars, Diners,...    0.975629  \n",
       "2  Dance Clubs, Sushi Bars, Restaurants, Bars, Ni...    0.975572  \n",
       "3  Arts & Entertainment, Nightlife, Comfort Food,...    0.973524  \n",
       "4  Sports Bars, Pubs, American (Traditional), Res...    0.973021  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_entertainment_venues = find_similar_businesses(\"Du Bowl Lanes\", 'Saint Louis', business_embeddings, df_businesses)\n",
    "similar_entertainment_venues_df = pd.DataFrame(similar_entertainment_venues, columns=['Name', 'Stars', 'Categories', 'Similarity'])\n",
    "\n",
    "print(\"Similar Entertainment Venues to 'Du Bowl Lanes' in Saint Louis:\")\n",
    "similar_entertainment_venues_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THANK YOU!"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4524012,
     "sourceId": 7753063,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
